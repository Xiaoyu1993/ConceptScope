<!DOCTYPE html>
<!-- saved from url=(0242)http://delivery.acm.org/10.1145/3310000/3300233/a3-amershi.html?ip=169.237.6.227&id=3300233&acc=ACTIVE%20SERVICE&key=CA367851C7E3CE77%2EBD0EBCE24FE9A3C5%2E4D4702B0C3E38B35%2E4D4702B0C3E38B35&__acm__=1575108223_4c676709117010e6d07bffafb2c8e6c5 -->
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <title>Guidelines for Human-AI Interaction</title> <!-- Copyright (c) 2010-2015 The MathJax Consortium --> <meta name="viewport" content="width=device-width; initial-scale=1.0;"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <link media="screen, print" rel="stylesheet" href="./paper-chi-algorithm-3_files/bootstrap.min.css"><link media="screen, print" rel="stylesheet" href="./paper-chi-algorithm-3_files/bootstrap-theme.min.css"><link media="screen, print" rel="stylesheet" href="./paper-chi-algorithm-3_files/main.css"><script src="./paper-chi-algorithm-3_files/jquery.min.js" type="text/javascript"></script> <script src="./paper-chi-algorithm-3_files/bootstrap.min.js" type="text/javascript"></script> <script src="./paper-chi-algorithm-3_files/bibCit.js" type="text/javascript"></script> <script src="./paper-chi-algorithm-3_files/divTab.js" type="text/javascript"></script> <script type="text/javascript" src="./paper-chi-algorithm-3_files/MathJax.js"></script> <script type="text/x-mathjax-config;executed=true">MathJax.Hub.Config({tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}});</script> <style type="text/css">.MathJax_Hover_Frame {border-radius: .25em; -webkit-border-radius: .25em; -moz-border-radius: .25em; -khtml-border-radius: .25em; box-shadow: 0px 0px 15px #83A; -webkit-box-shadow: 0px 0px 15px #83A; -moz-box-shadow: 0px 0px 15px #83A; -khtml-box-shadow: 0px 0px 15px #83A; border: 1px solid #A6D ! important; display: inline-block; position: absolute}
.MathJax_Menu_Button .MathJax_Hover_Arrow {position: absolute; cursor: pointer; display: inline-block; border: 2px solid #AAA; border-radius: 4px; -webkit-border-radius: 4px; -moz-border-radius: 4px; -khtml-border-radius: 4px; font-family: 'Courier New',Courier; font-size: 9px; color: #F0F0F0}
.MathJax_Menu_Button .MathJax_Hover_Arrow span {display: block; background-color: #AAA; border: 1px solid; border-radius: 3px; line-height: 0; padding: 4px}
.MathJax_Hover_Arrow:hover {color: white!important; border: 2px solid #CCC!important}
.MathJax_Hover_Arrow:hover span {background-color: #CCC!important}
</style><style type="text/css">#MathJax_About {position: fixed; left: 50%; width: auto; text-align: center; border: 3px outset; padding: 1em 2em; background-color: #DDDDDD; color: black; cursor: default; font-family: message-box; font-size: 120%; font-style: normal; text-indent: 0; text-transform: none; line-height: normal; letter-spacing: normal; word-spacing: normal; word-wrap: normal; white-space: nowrap; float: none; z-index: 201; border-radius: 15px; -webkit-border-radius: 15px; -moz-border-radius: 15px; -khtml-border-radius: 15px; box-shadow: 0px 10px 20px #808080; -webkit-box-shadow: 0px 10px 20px #808080; -moz-box-shadow: 0px 10px 20px #808080; -khtml-box-shadow: 0px 10px 20px #808080; filter: progid:DXImageTransform.Microsoft.dropshadow(OffX=2, OffY=2, Color='gray', Positive='true')}
#MathJax_About.MathJax_MousePost {outline: none}
.MathJax_Menu {position: absolute; background-color: white; color: black; width: auto; padding: 5px 0px; border: 1px solid #CCCCCC; margin: 0; cursor: default; font: menu; text-align: left; text-indent: 0; text-transform: none; line-height: normal; letter-spacing: normal; word-spacing: normal; word-wrap: normal; white-space: nowrap; float: none; z-index: 201; border-radius: 5px; -webkit-border-radius: 5px; -moz-border-radius: 5px; -khtml-border-radius: 5px; box-shadow: 0px 10px 20px #808080; -webkit-box-shadow: 0px 10px 20px #808080; -moz-box-shadow: 0px 10px 20px #808080; -khtml-box-shadow: 0px 10px 20px #808080; filter: progid:DXImageTransform.Microsoft.dropshadow(OffX=2, OffY=2, Color='gray', Positive='true')}
.MathJax_MenuItem {padding: 1px 2em; background: transparent}
.MathJax_MenuArrow {position: absolute; right: .5em; padding-top: .25em; color: #666666; font-size: .75em}
.MathJax_MenuActive .MathJax_MenuArrow {color: white}
.MathJax_MenuArrow.RTL {left: .5em; right: auto}
.MathJax_MenuCheck {position: absolute; left: .7em}
.MathJax_MenuCheck.RTL {right: .7em; left: auto}
.MathJax_MenuRadioCheck {position: absolute; left: .7em}
.MathJax_MenuRadioCheck.RTL {right: .7em; left: auto}
.MathJax_MenuLabel {padding: 1px 2em 3px 1.33em; font-style: italic}
.MathJax_MenuRule {border-top: 1px solid #DDDDDD; margin: 4px 3px}
.MathJax_MenuDisabled {color: GrayText}
.MathJax_MenuActive {background-color: #606872; color: white}
.MathJax_MenuDisabled:focus, .MathJax_MenuLabel:focus {background-color: #E8E8E8}
.MathJax_ContextMenu:focus {outline: none}
.MathJax_ContextMenu .MathJax_MenuItem:focus {outline: none}
#MathJax_AboutClose {top: .2em; right: .2em}
.MathJax_Menu .MathJax_MenuClose {top: -10px; left: -10px}
.MathJax_MenuClose {position: absolute; cursor: pointer; display: inline-block; border: 2px solid #AAA; border-radius: 18px; -webkit-border-radius: 18px; -moz-border-radius: 18px; -khtml-border-radius: 18px; font-family: 'Courier New',Courier; font-size: 24px; color: #F0F0F0}
.MathJax_MenuClose span {display: block; background-color: #AAA; border: 1.5px solid; border-radius: 18px; -webkit-border-radius: 18px; -moz-border-radius: 18px; -khtml-border-radius: 18px; line-height: 0; padding: 8px 0 6px}
.MathJax_MenuClose:hover {color: white!important; border: 2px solid #CCC!important}
.MathJax_MenuClose:hover span {background-color: #CCC!important}
.MathJax_MenuClose:hover:focus {outline: none}
</style><style type="text/css">.MathJax_Preview .MJXf-math {color: inherit!important}
</style><style type="text/css">.MJX_Assistive_MathML {position: absolute!important; top: 0; left: 0; clip: rect(1px, 1px, 1px, 1px); padding: 1px 0 0 0!important; border: 0!important; height: 1px!important; width: 1px!important; overflow: hidden!important; display: block!important; -webkit-touch-callout: none; -webkit-user-select: none; -khtml-user-select: none; -moz-user-select: none; -ms-user-select: none; user-select: none}
.MJX_Assistive_MathML.MJX_Assistive_MathML_Block {width: 100%!important}
</style><style type="text/css">#MathJax_Zoom {position: absolute; background-color: #F0F0F0; overflow: auto; display: block; z-index: 301; padding: .5em; border: 1px solid black; margin: 0; font-weight: normal; font-style: normal; text-align: left; text-indent: 0; text-transform: none; line-height: normal; letter-spacing: normal; word-spacing: normal; word-wrap: normal; white-space: nowrap; float: none; -webkit-box-sizing: content-box; -moz-box-sizing: content-box; box-sizing: content-box; box-shadow: 5px 5px 15px #AAAAAA; -webkit-box-shadow: 5px 5px 15px #AAAAAA; -moz-box-shadow: 5px 5px 15px #AAAAAA; -khtml-box-shadow: 5px 5px 15px #AAAAAA; filter: progid:DXImageTransform.Microsoft.dropshadow(OffX=2, OffY=2, Color='gray', Positive='true')}
#MathJax_ZoomOverlay {position: absolute; left: 0; top: 0; z-index: 300; display: inline-block; width: 100%; height: 100%; border: 0; padding: 0; margin: 0; background-color: white; opacity: 0; filter: alpha(opacity=0)}
#MathJax_ZoomFrame {position: relative; display: inline-block; height: 0; width: 0}
#MathJax_ZoomEventTrap {position: absolute; left: 0; top: 0; z-index: 302; display: inline-block; border: 0; padding: 0; margin: 0; background-color: white; opacity: 0; filter: alpha(opacity=0)}
</style><style type="text/css">.MathJax_Preview {color: #888}
#MathJax_Message {position: fixed; left: 1em; bottom: 1.5em; background-color: #E6E6E6; border: 1px solid #959595; margin: 0px; padding: 2px 8px; z-index: 102; color: black; font-size: 80%; width: auto; white-space: nowrap}
#MathJax_MSIE_Frame {position: absolute; top: 0; left: 0; width: 0px; z-index: 101; border: 0px; margin: 0px; padding: 0px}
.MathJax_Error {color: #CC0000; font-style: italic}
</style><style type="text/css">.MJXp-script {font-size: .8em}
.MJXp-right {-webkit-transform-origin: right; -moz-transform-origin: right; -ms-transform-origin: right; -o-transform-origin: right; transform-origin: right}
.MJXp-bold {font-weight: bold}
.MJXp-italic {font-style: italic}
.MJXp-scr {font-family: MathJax_Script,'Times New Roman',Times,STIXGeneral,serif}
.MJXp-frak {font-family: MathJax_Fraktur,'Times New Roman',Times,STIXGeneral,serif}
.MJXp-sf {font-family: MathJax_SansSerif,'Times New Roman',Times,STIXGeneral,serif}
.MJXp-cal {font-family: MathJax_Caligraphic,'Times New Roman',Times,STIXGeneral,serif}
.MJXp-mono {font-family: MathJax_Typewriter,'Times New Roman',Times,STIXGeneral,serif}
.MJXp-largeop {font-size: 150%}
.MJXp-largeop.MJXp-int {vertical-align: -.2em}
.MJXp-math {display: inline-block; line-height: 1.2; text-indent: 0; font-family: 'Times New Roman',Times,STIXGeneral,serif; white-space: nowrap; border-collapse: collapse}
.MJXp-display {display: block; text-align: center; margin: 1em 0}
.MJXp-math span {display: inline-block}
.MJXp-box {display: block!important; text-align: center}
.MJXp-box:after {content: " "}
.MJXp-rule {display: block!important; margin-top: .1em}
.MJXp-char {display: block!important}
.MJXp-mo {margin: 0 .15em}
.MJXp-mfrac {margin: 0 .125em; vertical-align: .25em}
.MJXp-denom {display: inline-table!important; width: 100%}
.MJXp-denom > * {display: table-row!important}
.MJXp-surd {vertical-align: top}
.MJXp-surd > * {display: block!important}
.MJXp-script-box > *  {display: table!important; height: 50%}
.MJXp-script-box > * > * {display: table-cell!important; vertical-align: top}
.MJXp-script-box > *:last-child > * {vertical-align: bottom}
.MJXp-script-box > * > * > * {display: block!important}
.MJXp-mphantom {visibility: hidden}
.MJXp-munderover {display: inline-table!important}
.MJXp-over {display: inline-block!important; text-align: center}
.MJXp-over > * {display: block!important}
.MJXp-munderover > * {display: table-row!important}
.MJXp-mtable {vertical-align: .25em; margin: 0 .125em}
.MJXp-mtable > * {display: inline-table!important; vertical-align: middle}
.MJXp-mtr {display: table-row!important}
.MJXp-mtd {display: table-cell!important; text-align: center; padding: .5em 0 0 .5em}
.MJXp-mtr > .MJXp-mtd:first-child {padding-left: 0}
.MJXp-mtr:first-child > .MJXp-mtd {padding-top: 0}
.MJXp-mlabeledtr {display: table-row!important}
.MJXp-mlabeledtr > .MJXp-mtd:first-child {padding-left: 0}
.MJXp-mlabeledtr:first-child > .MJXp-mtd {padding-top: 0}
.MJXp-merror {background-color: #FFFF88; color: #CC0000; border: 1px solid #CC0000; padding: 1px 3px; font-style: normal; font-size: 90%}
.MJXp-scale0 {-webkit-transform: scaleX(.0); -moz-transform: scaleX(.0); -ms-transform: scaleX(.0); -o-transform: scaleX(.0); transform: scaleX(.0)}
.MJXp-scale1 {-webkit-transform: scaleX(.1); -moz-transform: scaleX(.1); -ms-transform: scaleX(.1); -o-transform: scaleX(.1); transform: scaleX(.1)}
.MJXp-scale2 {-webkit-transform: scaleX(.2); -moz-transform: scaleX(.2); -ms-transform: scaleX(.2); -o-transform: scaleX(.2); transform: scaleX(.2)}
.MJXp-scale3 {-webkit-transform: scaleX(.3); -moz-transform: scaleX(.3); -ms-transform: scaleX(.3); -o-transform: scaleX(.3); transform: scaleX(.3)}
.MJXp-scale4 {-webkit-transform: scaleX(.4); -moz-transform: scaleX(.4); -ms-transform: scaleX(.4); -o-transform: scaleX(.4); transform: scaleX(.4)}
.MJXp-scale5 {-webkit-transform: scaleX(.5); -moz-transform: scaleX(.5); -ms-transform: scaleX(.5); -o-transform: scaleX(.5); transform: scaleX(.5)}
.MJXp-scale6 {-webkit-transform: scaleX(.6); -moz-transform: scaleX(.6); -ms-transform: scaleX(.6); -o-transform: scaleX(.6); transform: scaleX(.6)}
.MJXp-scale7 {-webkit-transform: scaleX(.7); -moz-transform: scaleX(.7); -ms-transform: scaleX(.7); -o-transform: scaleX(.7); transform: scaleX(.7)}
.MJXp-scale8 {-webkit-transform: scaleX(.8); -moz-transform: scaleX(.8); -ms-transform: scaleX(.8); -o-transform: scaleX(.8); transform: scaleX(.8)}
.MJXp-scale9 {-webkit-transform: scaleX(.9); -moz-transform: scaleX(.9); -ms-transform: scaleX(.9); -o-transform: scaleX(.9); transform: scaleX(.9)}
.MathJax_PHTML .noError {vertical-align: ; font-size: 90%; text-align: left; color: black; padding: 1px 3px; border: 1px solid}
</style></head> <body id="main"><div id="MathJax_Message" style="display: none;"></div><table width="100%"><tbody><tr><td><div class="utilities-area"><div class="logo-section"><div class="show-for-large-up"><a class="navbar-brand" href="http://www.acm.org/"> <img alt="ACM Logo" class="img-responsive" src="./paper-chi-algorithm-3_files/acm_logo.jpg"></a></div><div class="hide-for-large-up"><a class="navbar-brand" href="http://www.acm.org/"> <img alt="ACM Logo" class="img-responsive" src="./paper-chi-algorithm-3_files/acm_logo_mobile.jpg"></a></div></div></div></td></tr><tr height="50px"><td align="left"><button class="ArtNav" id="ArtNav" onclick="openNav(this)" tabindex="0"><span aria-hidden="true">☰</span><span class="ArticleNavi"> Article Navigation</span></button></td></tr></tbody></table> <div id="mySidenav" class="sidenav" aria-hidden="true" tabindex="-1" role="region" aria-labelledby="sidebar_title"><span id="sidebar_title" class="navHead" align="center">Article Navigation</span><a href="http://delivery.acm.org/10.1145/3310000/3300233/a3-amershi.html?ip=169.237.6.227&amp;id=3300233&amp;acc=ACTIVE%20SERVICE&amp;key=CA367851C7E3CE77%2EBD0EBCE24FE9A3C5%2E4D4702B0C3E38B35%2E4D4702B0C3E38B35&amp;__acm__=1575108223_4c676709117010e6d07bffafb2c8e6c5#" aria-label="Close article navigation" class="closebtn" onclick="closeNav(true)" tabindex="-1"><span aria-hidden="true">×</span></a><a href="http://delivery.acm.org/10.1145/3310000/3300233/a3-amershi.html?ip=169.237.6.227&amp;id=3300233&amp;acc=ACTIVE%20SERVICE&amp;key=CA367851C7E3CE77%2EBD0EBCE24FE9A3C5%2E4D4702B0C3E38B35%2E4D4702B0C3E38B35&amp;__acm__=1575108223_4c676709117010e6d07bffafb2c8e6c5#" class="navAbs" onclick="closeNav(false)" tabindex="-1">Abstract</a><hr><a class="navLista" onclick="closeNav(false)" style="display:list-item;" tabindex="-1" href="http://delivery.acm.org/10.1145/3310000/3300233/a3-amershi.html?ip=169.237.6.227&amp;id=3300233&amp;acc=ACTIVE%20SERVICE&amp;key=CA367851C7E3CE77%2EBD0EBCE24FE9A3C5%2E4D4702B0C3E38B35%2E4D4702B0C3E38B35&amp;__acm__=1575108223_4c676709117010e6d07bffafb2c8e6c5#sec-2"><span style="vertical-align: top;">1</span><span style="display:inline-block;margin-left:5px;width:80%">  INTRODUCTION</span></a><hr><a class="navLista" onclick="closeNav(false)" style="display:list-item;" tabindex="-1" href="http://delivery.acm.org/10.1145/3310000/3300233/a3-amershi.html?ip=169.237.6.227&amp;id=3300233&amp;acc=ACTIVE%20SERVICE&amp;key=CA367851C7E3CE77%2EBD0EBCE24FE9A3C5%2E4D4702B0C3E38B35%2E4D4702B0C3E38B35&amp;__acm__=1575108223_4c676709117010e6d07bffafb2c8e6c5#sec-3"><span style="vertical-align: top;">2</span><span style="display:inline-block;margin-left:5px;width:80%">  RELATED WORK</span></a><hr><a class="navLista" onclick="closeNav(false)" style="display:list-item;" tabindex="-1" href="http://delivery.acm.org/10.1145/3310000/3300233/a3-amershi.html?ip=169.237.6.227&amp;id=3300233&amp;acc=ACTIVE%20SERVICE&amp;key=CA367851C7E3CE77%2EBD0EBCE24FE9A3C5%2E4D4702B0C3E38B35%2E4D4702B0C3E38B35&amp;__acm__=1575108223_4c676709117010e6d07bffafb2c8e6c5#sec-4"><span style="vertical-align: top;">3</span><span style="display:inline-block;margin-left:5px;width:80%">  PHASE 1: CONSOLIDATING GUIDELINES</span></a><hr><a class="navLista" onclick="closeNav(false)" style="display:list-item;" tabindex="-1" href="http://delivery.acm.org/10.1145/3310000/3300233/a3-amershi.html?ip=169.237.6.227&amp;id=3300233&amp;acc=ACTIVE%20SERVICE&amp;key=CA367851C7E3CE77%2EBD0EBCE24FE9A3C5%2E4D4702B0C3E38B35%2E4D4702B0C3E38B35&amp;__acm__=1575108223_4c676709117010e6d07bffafb2c8e6c5#sec-5"><span style="vertical-align: top;">4</span><span style="display:inline-block;margin-left:5px;width:80%">  PHASE 2: MODIFIED HEURISTIC EVALUATION</span></a><hr><a class="navLista" onclick="closeNav(false)" style="display:list-item;" tabindex="-1" href="http://delivery.acm.org/10.1145/3310000/3300233/a3-amershi.html?ip=169.237.6.227&amp;id=3300233&amp;acc=ACTIVE%20SERVICE&amp;key=CA367851C7E3CE77%2EBD0EBCE24FE9A3C5%2E4D4702B0C3E38B35%2E4D4702B0C3E38B35&amp;__acm__=1575108223_4c676709117010e6d07bffafb2c8e6c5#sec-6"><span style="vertical-align: top;">5</span><span style="display:inline-block;margin-left:5px;width:80%">  PHASE 3: USER STUDY</span></a><a class="navLista" onclick="closeNav(false)" style="display:list-item;" tabindex="-1" href="http://delivery.acm.org/10.1145/3310000/3300233/a3-amershi.html?ip=169.237.6.227&amp;id=3300233&amp;acc=ACTIVE%20SERVICE&amp;key=CA367851C7E3CE77%2EBD0EBCE24FE9A3C5%2E4D4702B0C3E38B35%2E4D4702B0C3E38B35&amp;__acm__=1575108223_4c676709117010e6d07bffafb2c8e6c5#sec-7"> <span style="vertical-align: top;"> </span><span style="display:inline-block;margin-left:5px;width:80%">  Procedure</span></a><a class="navLista" onclick="closeNav(false)" style="display:list-item;" tabindex="-1" href="http://delivery.acm.org/10.1145/3310000/3300233/a3-amershi.html?ip=169.237.6.227&amp;id=3300233&amp;acc=ACTIVE%20SERVICE&amp;key=CA367851C7E3CE77%2EBD0EBCE24FE9A3C5%2E4D4702B0C3E38B35%2E4D4702B0C3E38B35&amp;__acm__=1575108223_4c676709117010e6d07bffafb2c8e6c5#sec-8"> <span style="vertical-align: top;"> </span><span style="display:inline-block;margin-left:5px;width:80%">  Products</span></a><a class="navLista" onclick="closeNav(false)" style="display:list-item;" tabindex="-1" href="http://delivery.acm.org/10.1145/3310000/3300233/a3-amershi.html?ip=169.237.6.227&amp;id=3300233&amp;acc=ACTIVE%20SERVICE&amp;key=CA367851C7E3CE77%2EBD0EBCE24FE9A3C5%2E4D4702B0C3E38B35%2E4D4702B0C3E38B35&amp;__acm__=1575108223_4c676709117010e6d07bffafb2c8e6c5#sec-9"> <span style="vertical-align: top;"> </span><span style="display:inline-block;margin-left:5px;width:80%">  Participants</span></a><a class="navLista" onclick="closeNav(false)" style="display:list-item;" tabindex="-1" href="http://delivery.acm.org/10.1145/3310000/3300233/a3-amershi.html?ip=169.237.6.227&amp;id=3300233&amp;acc=ACTIVE%20SERVICE&amp;key=CA367851C7E3CE77%2EBD0EBCE24FE9A3C5%2E4D4702B0C3E38B35%2E4D4702B0C3E38B35&amp;__acm__=1575108223_4c676709117010e6d07bffafb2c8e6c5#sec-10"> <span style="vertical-align: top;"> </span><span style="display:inline-block;margin-left:5px;width:80%">  Adjustments and Misinterpretations</span></a><a class="navLista" onclick="closeNav(false)" style="display:list-item;" tabindex="-1" href="http://delivery.acm.org/10.1145/3310000/3300233/a3-amershi.html?ip=169.237.6.227&amp;id=3300233&amp;acc=ACTIVE%20SERVICE&amp;key=CA367851C7E3CE77%2EBD0EBCE24FE9A3C5%2E4D4702B0C3E38B35%2E4D4702B0C3E38B35&amp;__acm__=1575108223_4c676709117010e6d07bffafb2c8e6c5#sec-11"> <span style="vertical-align: top;"> </span><span style="display:inline-block;margin-left:5px;width:80%">  Results</span></a><a class="navLista" onclick="closeNav(false)" style="display:list-item;" tabindex="-1" href="http://delivery.acm.org/10.1145/3310000/3300233/a3-amershi.html?ip=169.237.6.227&amp;id=3300233&amp;acc=ACTIVE%20SERVICE&amp;key=CA367851C7E3CE77%2EBD0EBCE24FE9A3C5%2E4D4702B0C3E38B35%2E4D4702B0C3E38B35&amp;__acm__=1575108223_4c676709117010e6d07bffafb2c8e6c5#sec-13">  <span style="vertical-align: top;"> </span><span style="display:inline-block;margin-left:5px;width:80%">  Clarity and Clarifications.</span></a><hr><a class="navLista" onclick="closeNav(false)" style="display:list-item;" tabindex="-1" href="http://delivery.acm.org/10.1145/3310000/3300233/a3-amershi.html?ip=169.237.6.227&amp;id=3300233&amp;acc=ACTIVE%20SERVICE&amp;key=CA367851C7E3CE77%2EBD0EBCE24FE9A3C5%2E4D4702B0C3E38B35%2E4D4702B0C3E38B35&amp;__acm__=1575108223_4c676709117010e6d07bffafb2c8e6c5#sec-14"><span style="vertical-align: top;">6</span><span style="display:inline-block;margin-left:5px;width:80%">  PHASE 4: EXPERT EVALUATION OF REVISIONS</span></a><hr><a class="navLista" onclick="closeNav(false)" style="display:list-item;" tabindex="-1" href="http://delivery.acm.org/10.1145/3310000/3300233/a3-amershi.html?ip=169.237.6.227&amp;id=3300233&amp;acc=ACTIVE%20SERVICE&amp;key=CA367851C7E3CE77%2EBD0EBCE24FE9A3C5%2E4D4702B0C3E38B35%2E4D4702B0C3E38B35&amp;__acm__=1575108223_4c676709117010e6d07bffafb2c8e6c5#sec-15"><span style="vertical-align: top;">7</span><span style="display:inline-block;margin-left:5px;width:80%">  Discussion &amp; Future Work</span></a><hr><a class="navLista" onclick="closeNav(false)" style="display:list-item;" tabindex="-1" href="http://delivery.acm.org/10.1145/3310000/3300233/a3-amershi.html?ip=169.237.6.227&amp;id=3300233&amp;acc=ACTIVE%20SERVICE&amp;key=CA367851C7E3CE77%2EBD0EBCE24FE9A3C5%2E4D4702B0C3E38B35%2E4D4702B0C3E38B35&amp;__acm__=1575108223_4c676709117010e6d07bffafb2c8e6c5#sec-16"><span style="vertical-align: top;">8</span><span style="display:inline-block;margin-left:5px;width:80%">  CONCLUSION</span></a><hr><a class="navLista" onclick="closeNav(false)" style="display:list-item;" tabindex="-1" href="http://delivery.acm.org/10.1145/3310000/3300233/a3-amershi.html?ip=169.237.6.227&amp;id=3300233&amp;acc=ACTIVE%20SERVICE&amp;key=CA367851C7E3CE77%2EBD0EBCE24FE9A3C5%2E4D4702B0C3E38B35%2E4D4702B0C3E38B35&amp;__acm__=1575108223_4c676709117010e6d07bffafb2c8e6c5#sec-17"><span style="vertical-align: top;">9</span><span style="display:inline-block;margin-left:5px;width:80%">  ACKNOWLEDGMENTS</span></a><hr><a class="navLista" onclick="closeNav(false)" style="display:list-item;" tabindex="-1" href="http://delivery.acm.org/10.1145/3310000/3300233/a3-amershi.html?ip=169.237.6.227&amp;id=3300233&amp;acc=ACTIVE%20SERVICE&amp;key=CA367851C7E3CE77%2EBD0EBCE24FE9A3C5%2E4D4702B0C3E38B35%2E4D4702B0C3E38B35&amp;__acm__=1575108223_4c676709117010e6d07bffafb2c8e6c5#ref-001"><span style="vertical-align: top;"></span><span style="display:inline-block;margin-left:5px;width:80%">REFERENCES</span></a><hr><a class="navLista" onclick="closeNav(false)" style="display:list-item;" tabindex="-1" href="http://delivery.acm.org/10.1145/3310000/3300233/a3-amershi.html?ip=169.237.6.227&amp;id=3300233&amp;acc=ACTIVE%20SERVICE&amp;key=CA367851C7E3CE77%2EBD0EBCE24FE9A3C5%2E4D4702B0C3E38B35%2E4D4702B0C3E38B35&amp;__acm__=1575108223_4c676709117010e6d07bffafb2c8e6c5#foot-001"><span style="vertical-align: top;"></span><span style="display:inline-block;margin-left:5px;width:80%">FOOTNOTE</span></a></div><section class="front-matter"> <section> <header class="title-info"> <div class="journal-title"> <h1> <span class="title">Guidelines for Human-AI Interaction</span> <br> <span class="subTitle"> </span></h1> </div> </header> <div class="authorGroup"> <div class="author"> <span class="givenName">Saleema</span> <span class="surName">Amershi</span>, Microsoft Research, USA, <a href="mailto:samershi@microsoft.com">samershi@microsoft.com</a> </div> <div class="author"> <span class="givenName">Dan</span> <span class="surName">Weld</span>, University of Washington, USA, <a href="mailto:weld@cs.washington.edu">weld@cs.washington.edu</a> </div> <div class="author"> <span class="givenName">Mihaela</span> <span class="surName">Vorvoreanu</span>, Microsoft Research, USA, <a href="mailto:mihaela.vorvoreanu@microsoft.com">mihaela.vorvoreanu@microsoft.com</a> </div> <div class="author"> <span class="givenName">Adam</span> <span class="surName">Fourney</span>, Microsoft Research, USA, <a href="mailto:adamfo@microsoft.com">adamfo@microsoft.com</a> </div> <div class="author"> <span class="givenName">Besmira</span> <span class="surName">Nushi</span>, Microsoft Research, USA, <a href="mailto:besmira.nushi@microsoft.com">besmira.nushi@microsoft.com</a> </div> <div class="author"> <span class="givenName">Penny</span> <span class="surName">Collisson</span>, Microsoft, USA, <a href="mailto:pennycol@microsoft.com">pennycol@microsoft.com</a> </div> <div class="author"> <span class="givenName">Jina</span> <span class="surName">Suh</span>, Microsoft Research, USA, <a href="mailto:jinsuh@microsoft.com">jinsuh@microsoft.com</a> </div> <div class="author"> <span class="givenName">Shamsi</span> <span class="surName">Iqbal</span>, Microsoft Research, USA, <a href="mailto:shamsi@microsoft.com">shamsi@microsoft.com</a> </div> <div class="author"> <span class="givenName">Paul</span> <span class="surName">N. Bennett</span>, Microsoft Research, USA, <a href="mailto:pauben@microsoft.com">pauben@microsoft.com</a> </div> <div class="author"> <span class="givenName">Kori</span> <span class="surName">Inkpen</span>, Microsoft, USA, <a href="mailto:kori@microsoft.com">kori@microsoft.com</a> </div> <div class="author"> <span class="givenName">Jaime</span> <span class="surName">Teevan</span>, Microsoft Research, USA, <a href="mailto:teevan@microsoft.com">teevan@microsoft.com</a> </div> <div class="author"> <span class="givenName">Ruth</span> <span class="surName">Kikin-Gil</span>, Microsoft, USA, <a href="mailto:ruthkg@microsoft.com">ruthkg@microsoft.com</a> </div> <div class="author"> <span class="givenName">Eric</span> <span class="surName">Horvitz</span>, Microsoft Research, USA, <a href="mailto:horvitz@microsoft.com">horvitz@microsoft.com</a> </div> </div> <br> <div class="pubInfo"> <p>DOI: <a href="https://doi.org/10.1145/3290605.3300233" target="_blank">https://doi.org/10.1145/3290605.3300233</a> <br>CHI '19: <a href="https://doi.org/10.1145/3290605" target="_blank">Proceedings of CHI Conference on Human Factors in Computing Systems</a>, Glasgow, Scotland UK, May 2019</p> </div> <div class="abstract"> <p><small>Advances in artificial intelligence (AI) frame opportunities and challenges for user interface design. Principles for human-AI interaction have been discussed in the human-computer interaction community for over two decades, but more study and innovation are needed in light of advances in AI and the growing uses of AI technologies in human-facing applications. We propose 18 generally applicable design guidelines for human-AI interaction. These guidelines are validated through multiple rounds of evaluation including a user study with 49 design practitioners who tested the guidelines against 20 popular AI-infused products. The results verify the relevance of the guidelines over a spectrum of interaction scenarios and reveal gaps in our knowledge, highlighting opportunities for further research. Based on the evaluations, we believe the set of design guidelines can serve as a resource to practitioners working on the design of applications and features that harness AI technologies, and to researchers interested in the further development of guidelines for human-AI interaction design.</small></p> </div> <div class="CCSconcepts"> <ccs2012><small> <span style="font-weight:bold;">CCS Concepts:</span> • <strong>Human-centered computing → Human computer interaction (HCI)</strong>; • <strong>Computing methodologies → Artificial intelligence</strong>;</small> </ccs2012> </div> <br> <div class="classifications"> <div class="author"> <span style="font-weight:bold;"><small>Keywords:</small></span> <span class="keyword"><small>Human-AI interaction; AI-infused systems; design guidelines</small></span> </div> <br> <div class="AcmReferenceFormat"> <p><small> <span style="font-weight:bold;">ACM Reference Format:</span> <br>Saleema Amershi, Dan Weld, Mihaela Vorvoreanu, Adam Fourney, Besmira Nushi, Penny Collisson, Jina Suh, Shamsi Iqbal, Paul N. Bennett, Kori Inkpen, Jaime Teevan, Ruth Kikin-Gil, and Eric Horvitz. 2019. Guidelines for Human-AI Interaction. In <em>Proceedings of CHI Conference on Human Factors in Computing Systems (CHI '19), May 4–9, 2019, Glasgow, Scotland UK.</em> ACM, New York, NY, USA 14 Pages. <a href="https://doi.org/10.1145/3290605.3300233" class="link-inline force-break" target="_blank">https://doi.org/10.1145/3290605.3300233</a></small></p> </div> </div> </section> </section> <section class="body"> <section id="sec-2"> <header> <div class="title-info"> <h2> <span class="section-number"><span class="nav-open" id="nav-open" onclick="openNav(this)" title="navigate to" tabindex="0">1</span></span> INTRODUCTION</h2> </div> </header> <p>Advances in artificial intelligence (AI) are enabling developers to integrate a variety of AI capabilities into user-facing systems. For example, increases in the accuracy of pattern recognition have created opportunities and pressure to integrate speech recognition, translation, object recognition, and face recognition into applications. However, as automated inferences are typically performed under uncertainty, often producing false positives and false negatives, AI-infused systems may demonstrate unpredictable behaviors that can be disruptive, confusing, offensive, and even dangerous. While some AI technologies are deployed in explicit, interactive uses, other advances are employed behind the scenes in proactive services acting on behalf of users such as automatically filtering content based on inferred relevance or importance. While such attempts at personalization may be delightful when aligned with users’ preferences, automated filtering and routing can be the source of costly information hiding and actions at odds with user goals and expectations.</p> <p><em>AI-infused systems</em><a class="fn" href="http://delivery.acm.org/10.1145/3310000/3300233/a3-amershi.html?ip=169.237.6.227&amp;id=3300233&amp;acc=ACTIVE%20SERVICE&amp;key=CA367851C7E3CE77%2EBD0EBCE24FE9A3C5%2E4D4702B0C3E38B35%2E4D4702B0C3E38B35&amp;__acm__=1575108223_4c676709117010e6d07bffafb2c8e6c5#fn2" id="foot-fn2" data-original-title="" title=""><sup>1</sup></a> can violate established usability guidelines of traditional user interface design (e.g., [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="http://delivery.acm.org/10.1145/3310000/3300233/a3-amershi.html?ip=169.237.6.227&amp;id=3300233&amp;acc=ACTIVE%20SERVICE&amp;key=CA367851C7E3CE77%2EBD0EBCE24FE9A3C5%2E4D4702B0C3E38B35%2E4D4702B0C3E38B35&amp;__acm__=1575108223_4c676709117010e6d07bffafb2c8e6c5#BibPLXBIB0031" data-original-title="" title="" id="auto-BibPLXBIB00311">31</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="http://delivery.acm.org/10.1145/3310000/3300233/a3-amershi.html?ip=169.237.6.227&amp;id=3300233&amp;acc=ACTIVE%20SERVICE&amp;key=CA367851C7E3CE77%2EBD0EBCE24FE9A3C5%2E4D4702B0C3E38B35%2E4D4702B0C3E38B35&amp;__acm__=1575108223_4c676709117010e6d07bffafb2c8e6c5#BibPLXBIB0032" data-original-title="" title="" id="auto-BibPLXBIB00322">32</a>]). For example, the principle of consistency advocates for minimizing unexpected changes with a consistent interface appearance and predictable behaviors. However, many AI components are inherently inconsistent due to poorly understood, probabilistic behaviors based on nuances of tasks and settings, and because they change via learning over time. AI-infused systems may react differently depending on lighting or noise conditions that are not recognized as distinct to end users. Systems may respond differently to the same text input over time (e.g., autocompletion systems suggesting different words after language model updates) or behave differently from one user to the next (e.g., search engines returning different results due to personalization). Inconsistent and unpredictable behaviors can confuse users, erode their confidence, and lead to abandonment of AI technology [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="http://delivery.acm.org/10.1145/3310000/3300233/a3-amershi.html?ip=169.237.6.227&amp;id=3300233&amp;acc=ACTIVE%20SERVICE&amp;key=CA367851C7E3CE77%2EBD0EBCE24FE9A3C5%2E4D4702B0C3E38B35%2E4D4702B0C3E38B35&amp;__acm__=1575108223_4c676709117010e6d07bffafb2c8e6c5#BibPLXBIB0007" data-original-title="" title="" id="auto-BibPLXBIB00073">7</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="http://delivery.acm.org/10.1145/3310000/3300233/a3-amershi.html?ip=169.237.6.227&amp;id=3300233&amp;acc=ACTIVE%20SERVICE&amp;key=CA367851C7E3CE77%2EBD0EBCE24FE9A3C5%2E4D4702B0C3E38B35%2E4D4702B0C3E38B35&amp;__acm__=1575108223_4c676709117010e6d07bffafb2c8e6c5#BibPLXBIB0022" data-original-title="" title="" id="auto-BibPLXBIB00224">22</a>]. Errors are common in AI-infused systems, rendering it difficult to reliably achieve the principle of error prevention. This has contributed to the large and growing body of work on AI explanations and interpretability to support human verification of proposed actions aimed at reducing the likelihood of unwarranted or potentially dangerous actions and costly outcomes (e.g., [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="http://delivery.acm.org/10.1145/3310000/3300233/a3-amershi.html?ip=169.237.6.227&amp;id=3300233&amp;acc=ACTIVE%20SERVICE&amp;key=CA367851C7E3CE77%2EBD0EBCE24FE9A3C5%2E4D4702B0C3E38B35%2E4D4702B0C3E38B35&amp;__acm__=1575108223_4c676709117010e6d07bffafb2c8e6c5#BibPLXBIB0014" data-original-title="" title="" id="auto-BibPLXBIB00145">14</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="http://delivery.acm.org/10.1145/3310000/3300233/a3-amershi.html?ip=169.237.6.227&amp;id=3300233&amp;acc=ACTIVE%20SERVICE&amp;key=CA367851C7E3CE77%2EBD0EBCE24FE9A3C5%2E4D4702B0C3E38B35%2E4D4702B0C3E38B35&amp;__acm__=1575108223_4c676709117010e6d07bffafb2c8e6c5#BibPLXBIB0021" data-original-title="" title="" id="auto-BibPLXBIB00216">21</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="http://delivery.acm.org/10.1145/3310000/3300233/a3-amershi.html?ip=169.237.6.227&amp;id=3300233&amp;acc=ACTIVE%20SERVICE&amp;key=CA367851C7E3CE77%2EBD0EBCE24FE9A3C5%2E4D4702B0C3E38B35%2E4D4702B0C3E38B35&amp;__acm__=1575108223_4c676709117010e6d07bffafb2c8e6c5#BibPLXBIB0023" data-original-title="" title="" id="auto-BibPLXBIB00237">23</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="http://delivery.acm.org/10.1145/3310000/3300233/a3-amershi.html?ip=169.237.6.227&amp;id=3300233&amp;acc=ACTIVE%20SERVICE&amp;key=CA367851C7E3CE77%2EBD0EBCE24FE9A3C5%2E4D4702B0C3E38B35%2E4D4702B0C3E38B35&amp;__acm__=1575108223_4c676709117010e6d07bffafb2c8e6c5#BibPLXBIB0036" data-original-title="" title="" id="auto-BibPLXBIB00368">36</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="http://delivery.acm.org/10.1145/3310000/3300233/a3-amershi.html?ip=169.237.6.227&amp;id=3300233&amp;acc=ACTIVE%20SERVICE&amp;key=CA367851C7E3CE77%2EBD0EBCE24FE9A3C5%2E4D4702B0C3E38B35%2E4D4702B0C3E38B35&amp;__acm__=1575108223_4c676709117010e6d07bffafb2c8e6c5#BibPLXBIB0038" data-original-title="" title="" id="auto-BibPLXBIB00389">38</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="http://delivery.acm.org/10.1145/3310000/3300233/a3-amershi.html?ip=169.237.6.227&amp;id=3300233&amp;acc=ACTIVE%20SERVICE&amp;key=CA367851C7E3CE77%2EBD0EBCE24FE9A3C5%2E4D4702B0C3E38B35%2E4D4702B0C3E38B35&amp;__acm__=1575108223_4c676709117010e6d07bffafb2c8e6c5#BibPLXBIB0044" data-original-title="" title="" id="auto-BibPLXBIB004410">44</a>]).</p> <p>For over 20 years, the human-computer interaction (HCI) community has proposed principles, guidelines, and strategies for designing user interfaces and interaction for applications employing AI inferences (e.g., [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="http://delivery.acm.org/10.1145/3310000/3300233/a3-amershi.html?ip=169.237.6.227&amp;id=3300233&amp;acc=ACTIVE%20SERVICE&amp;key=CA367851C7E3CE77%2EBD0EBCE24FE9A3C5%2E4D4702B0C3E38B35%2E4D4702B0C3E38B35&amp;__acm__=1575108223_4c676709117010e6d07bffafb2c8e6c5#BibPLXBIB0016" data-original-title="" title="" id="auto-BibPLXBIB001611">16</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="http://delivery.acm.org/10.1145/3310000/3300233/a3-amershi.html?ip=169.237.6.227&amp;id=3300233&amp;acc=ACTIVE%20SERVICE&amp;key=CA367851C7E3CE77%2EBD0EBCE24FE9A3C5%2E4D4702B0C3E38B35%2E4D4702B0C3E38B35&amp;__acm__=1575108223_4c676709117010e6d07bffafb2c8e6c5#BibPLXBIB0017" data-original-title="" title="" id="auto-BibPLXBIB001712">17</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="http://delivery.acm.org/10.1145/3310000/3300233/a3-amershi.html?ip=169.237.6.227&amp;id=3300233&amp;acc=ACTIVE%20SERVICE&amp;key=CA367851C7E3CE77%2EBD0EBCE24FE9A3C5%2E4D4702B0C3E38B35%2E4D4702B0C3E38B35&amp;__acm__=1575108223_4c676709117010e6d07bffafb2c8e6c5#BibPLXBIB0033" data-original-title="" title="" id="auto-BibPLXBIB003313">33</a>]). However, the variability of AI designs (e.g., varying capabilities and interaction styles of commercial conversational agents impacting user engagement and usability [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="http://delivery.acm.org/10.1145/3310000/3300233/a3-amershi.html?ip=169.237.6.227&amp;id=3300233&amp;acc=ACTIVE%20SERVICE&amp;key=CA367851C7E3CE77%2EBD0EBCE24FE9A3C5%2E4D4702B0C3E38B35%2E4D4702B0C3E38B35&amp;__acm__=1575108223_4c676709117010e6d07bffafb2c8e6c5#BibPLXBIB0026" data-original-title="" title="" id="auto-BibPLXBIB002614">26</a>]) and high-profile reports of failures, ranging from humorous and embarrassing (e.g., autocompletion errors [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="http://delivery.acm.org/10.1145/3310000/3300233/a3-amershi.html?ip=169.237.6.227&amp;id=3300233&amp;acc=ACTIVE%20SERVICE&amp;key=CA367851C7E3CE77%2EBD0EBCE24FE9A3C5%2E4D4702B0C3E38B35%2E4D4702B0C3E38B35&amp;__acm__=1575108223_4c676709117010e6d07bffafb2c8e6c5#BibPLXBIB0008" data-original-title="" title="" id="auto-BibPLXBIB000815">8</a>]) to more serious harm when users cannot effectively understand or control an AI system (e.g., collaboration with semi-autonomous cars [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="http://delivery.acm.org/10.1145/3310000/3300233/a3-amershi.html?ip=169.237.6.227&amp;id=3300233&amp;acc=ACTIVE%20SERVICE&amp;key=CA367851C7E3CE77%2EBD0EBCE24FE9A3C5%2E4D4702B0C3E38B35%2E4D4702B0C3E38B35&amp;__acm__=1575108223_4c676709117010e6d07bffafb2c8e6c5#BibPLXBIB0041" data-original-title="" title="" id="auto-BibPLXBIB004116">41</a>]), show that designers and developers continue to struggle with creating intuitive and effective AI-infused systems. Ongoing advances in AI technologies will generate a stream of challenges and opportunities for the HCI community. While such developments will require ongoing studies and vigilance, we also see value in developing reusable guidelines that can be shared, refined, and debated by the HCI community. The development and use of such shared guidelines can help with the design and evaluation of AI-infused systems that people can understand, trust, and can engage with effectively.</p> <p>In this work, we synthesize over 20 years of learning in AI design into a small set of generally applicable design guidelines for human-AI interaction. Specifically, our contributions are:</p> <ul class="list-no-style"> <li id="list1" label="•">A codification of over 150 AI-related design recommendations collected from academic and industry sources into a set of 18 generally applicable design guidelines for human-AI interaction (see Table <a class="tbl" href="http://delivery.acm.org/10.1145/3310000/3300233/a3-amershi.html?ip=169.237.6.227&amp;id=3300233&amp;acc=ACTIVE%20SERVICE&amp;key=CA367851C7E3CE77%2EBD0EBCE24FE9A3C5%2E4D4702B0C3E38B35%2E4D4702B0C3E38B35&amp;__acm__=1575108223_4c676709117010e6d07bffafb2c8e6c5#tab1">1</a>).<br></li> <li id="list2" label="•">A systematic validation of the 18 guidelines through multiple rounds of iteration and testing.<br></li> </ul> <p>We hope these guidelines, along with our examination of their applications in AI-infused systems, will serve as a resource for designers working with AI and will facilitate future research into the refinement and development of principles for human-AI interaction.</p> <div class="table-responsive" id="tab1"> <div class="table-caption"> <span class="table-number">Table 1:</span> <span class="table-title">Our 18 human-AI interaction design guidelines, roughly categorized by when they likely are to be applied during interaction with users, along with illustrative applications (rated as “clearly applied” by participants) across products tested by participants in our user study.</span> </div> <table class="table"> <tbody> <tr> <td> <img src="./paper-chi-algorithm-3_files/chi19-3-img1.svg" class="img-responsive" alt=""> </td> </tr> </tbody> </table> </div> </section> <section id="sec-3"> <header> <div class="title-info"> <h2> <span class="section-number"><span class="nav-open" id="nav-open" onclick="openNav(this)" title="navigate to" tabindex="0">2</span></span> RELATED WORK</h2> </div> </header> <p>For over 20 years, the academic community has proposed numerous guidelines and recommendations for how to design for effective human interaction with AI-infused systems. For example, Norman [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="http://delivery.acm.org/10.1145/3310000/3300233/a3-amershi.html?ip=169.237.6.227&amp;id=3300233&amp;acc=ACTIVE%20SERVICE&amp;key=CA367851C7E3CE77%2EBD0EBCE24FE9A3C5%2E4D4702B0C3E38B35%2E4D4702B0C3E38B35&amp;__acm__=1575108223_4c676709117010e6d07bffafb2c8e6c5#BibPLXBIB0033" data-original-title="" title="" id="auto-BibPLXBIB003317">33</a>] and Höök [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="http://delivery.acm.org/10.1145/3310000/3300233/a3-amershi.html?ip=169.237.6.227&amp;id=3300233&amp;acc=ACTIVE%20SERVICE&amp;key=CA367851C7E3CE77%2EBD0EBCE24FE9A3C5%2E4D4702B0C3E38B35%2E4D4702B0C3E38B35&amp;__acm__=1575108223_4c676709117010e6d07bffafb2c8e6c5#BibPLXBIB0016" data-original-title="" title="" id="auto-BibPLXBIB001618">16</a>] both recommended building in safeguards like verification steps or controlling levels of autonomy to help prevent unwanted adaptations or actions from intelligent systems. Others recommended managing expectations so as not to mislead or frustrate users during interaction with unpredictable adaptive agents [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="http://delivery.acm.org/10.1145/3310000/3300233/a3-amershi.html?ip=169.237.6.227&amp;id=3300233&amp;acc=ACTIVE%20SERVICE&amp;key=CA367851C7E3CE77%2EBD0EBCE24FE9A3C5%2E4D4702B0C3E38B35%2E4D4702B0C3E38B35&amp;__acm__=1575108223_4c676709117010e6d07bffafb2c8e6c5#BibPLXBIB0016" data-original-title="" title="" id="auto-BibPLXBIB001619">16</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="http://delivery.acm.org/10.1145/3310000/3300233/a3-amershi.html?ip=169.237.6.227&amp;id=3300233&amp;acc=ACTIVE%20SERVICE&amp;key=CA367851C7E3CE77%2EBD0EBCE24FE9A3C5%2E4D4702B0C3E38B35%2E4D4702B0C3E38B35&amp;__acm__=1575108223_4c676709117010e6d07bffafb2c8e6c5#BibPLXBIB0020" data-original-title="" title="" id="auto-BibPLXBIB002020">20</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="http://delivery.acm.org/10.1145/3310000/3300233/a3-amershi.html?ip=169.237.6.227&amp;id=3300233&amp;acc=ACTIVE%20SERVICE&amp;key=CA367851C7E3CE77%2EBD0EBCE24FE9A3C5%2E4D4702B0C3E38B35%2E4D4702B0C3E38B35&amp;__acm__=1575108223_4c676709117010e6d07bffafb2c8e6c5#BibPLXBIB0033" data-original-title="" title="" id="auto-BibPLXBIB003321">33</a>]. Horvitz's formative paper on mixed-initiative systems [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="http://delivery.acm.org/10.1145/3310000/3300233/a3-amershi.html?ip=169.237.6.227&amp;id=3300233&amp;acc=ACTIVE%20SERVICE&amp;key=CA367851C7E3CE77%2EBD0EBCE24FE9A3C5%2E4D4702B0C3E38B35%2E4D4702B0C3E38B35&amp;__acm__=1575108223_4c676709117010e6d07bffafb2c8e6c5#BibPLXBIB0017" data-original-title="" title="" id="auto-BibPLXBIB001722">17</a>] proposed principles for balancing autonomous actions with direct manipulation constructs, such as supporting user-driven invocation of intelligent services, scoping actions based on inferred goals and confidences, and inferring ideal action in light of costs, benefits, and uncertainties. The latter guideline was operationalized via the introduction of a decision-theoretic methodology to guide decisions about acting on AI inferences versus waiting for user input, based on consideration of expected costs and benefits of performing AI automation under uncertainty.</p> <p>In some cases, specific AI design recommendations have received considerable attention within the academic community. For example, a large body of work exists and continues to grow around how to increase transparency or explain the behaviors of AI systems (e.g., [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="http://delivery.acm.org/10.1145/3310000/3300233/a3-amershi.html?ip=169.237.6.227&amp;id=3300233&amp;acc=ACTIVE%20SERVICE&amp;key=CA367851C7E3CE77%2EBD0EBCE24FE9A3C5%2E4D4702B0C3E38B35%2E4D4702B0C3E38B35&amp;__acm__=1575108223_4c676709117010e6d07bffafb2c8e6c5#BibPLXBIB0014" data-original-title="" title="" id="auto-BibPLXBIB001423">14</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="http://delivery.acm.org/10.1145/3310000/3300233/a3-amershi.html?ip=169.237.6.227&amp;id=3300233&amp;acc=ACTIVE%20SERVICE&amp;key=CA367851C7E3CE77%2EBD0EBCE24FE9A3C5%2E4D4702B0C3E38B35%2E4D4702B0C3E38B35&amp;__acm__=1575108223_4c676709117010e6d07bffafb2c8e6c5#BibPLXBIB0021" data-original-title="" title="" id="auto-BibPLXBIB002124">21</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="http://delivery.acm.org/10.1145/3310000/3300233/a3-amershi.html?ip=169.237.6.227&amp;id=3300233&amp;acc=ACTIVE%20SERVICE&amp;key=CA367851C7E3CE77%2EBD0EBCE24FE9A3C5%2E4D4702B0C3E38B35%2E4D4702B0C3E38B35&amp;__acm__=1575108223_4c676709117010e6d07bffafb2c8e6c5#BibPLXBIB0023" data-original-title="" title="" id="auto-BibPLXBIB002325">23</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="http://delivery.acm.org/10.1145/3310000/3300233/a3-amershi.html?ip=169.237.6.227&amp;id=3300233&amp;acc=ACTIVE%20SERVICE&amp;key=CA367851C7E3CE77%2EBD0EBCE24FE9A3C5%2E4D4702B0C3E38B35%2E4D4702B0C3E38B35&amp;__acm__=1575108223_4c676709117010e6d07bffafb2c8e6c5#BibPLXBIB0036" data-original-title="" title="" id="auto-BibPLXBIB003626">36</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="http://delivery.acm.org/10.1145/3310000/3300233/a3-amershi.html?ip=169.237.6.227&amp;id=3300233&amp;acc=ACTIVE%20SERVICE&amp;key=CA367851C7E3CE77%2EBD0EBCE24FE9A3C5%2E4D4702B0C3E38B35%2E4D4702B0C3E38B35&amp;__acm__=1575108223_4c676709117010e6d07bffafb2c8e6c5#BibPLXBIB0038" data-original-title="" title="" id="auto-BibPLXBIB003827">38</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="http://delivery.acm.org/10.1145/3310000/3300233/a3-amershi.html?ip=169.237.6.227&amp;id=3300233&amp;acc=ACTIVE%20SERVICE&amp;key=CA367851C7E3CE77%2EBD0EBCE24FE9A3C5%2E4D4702B0C3E38B35%2E4D4702B0C3E38B35&amp;__acm__=1575108223_4c676709117010e6d07bffafb2c8e6c5#BibPLXBIB0044" data-original-title="" title="" id="auto-BibPLXBIB004428">44</a>], to name a few). Similarly, when and how to automatically adapt or personalize interfaces has been studied extensively in a variety of scenarios (e.g., [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="http://delivery.acm.org/10.1145/3310000/3300233/a3-amershi.html?ip=169.237.6.227&amp;id=3300233&amp;acc=ACTIVE%20SERVICE&amp;key=CA367851C7E3CE77%2EBD0EBCE24FE9A3C5%2E4D4702B0C3E38B35%2E4D4702B0C3E38B35&amp;__acm__=1575108223_4c676709117010e6d07bffafb2c8e6c5#BibPLXBIB0009" data-original-title="" title="" id="auto-BibPLXBIB000929">9</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="http://delivery.acm.org/10.1145/3310000/3300233/a3-amershi.html?ip=169.237.6.227&amp;id=3300233&amp;acc=ACTIVE%20SERVICE&amp;key=CA367851C7E3CE77%2EBD0EBCE24FE9A3C5%2E4D4702B0C3E38B35%2E4D4702B0C3E38B35&amp;__acm__=1575108223_4c676709117010e6d07bffafb2c8e6c5#BibPLXBIB0011" data-original-title="" title="" id="auto-BibPLXBIB001130">11</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="http://delivery.acm.org/10.1145/3310000/3300233/a3-amershi.html?ip=169.237.6.227&amp;id=3300233&amp;acc=ACTIVE%20SERVICE&amp;key=CA367851C7E3CE77%2EBD0EBCE24FE9A3C5%2E4D4702B0C3E38B35%2E4D4702B0C3E38B35&amp;__acm__=1575108223_4c676709117010e6d07bffafb2c8e6c5#BibPLXBIB0012" data-original-title="" title="" id="auto-BibPLXBIB001231">12</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="http://delivery.acm.org/10.1145/3310000/3300233/a3-amershi.html?ip=169.237.6.227&amp;id=3300233&amp;acc=ACTIVE%20SERVICE&amp;key=CA367851C7E3CE77%2EBD0EBCE24FE9A3C5%2E4D4702B0C3E38B35%2E4D4702B0C3E38B35&amp;__acm__=1575108223_4c676709117010e6d07bffafb2c8e6c5#BibPLXBIB0013" data-original-title="" title="" id="auto-BibPLXBIB001332">13</a>]).</p> <p>Others in the community have studied how to design for specific human-AI interaction scenarios. For example, researchers have been studying how to effectively interact with intelligent agents for many years (e.g., [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="http://delivery.acm.org/10.1145/3310000/3300233/a3-amershi.html?ip=169.237.6.227&amp;id=3300233&amp;acc=ACTIVE%20SERVICE&amp;key=CA367851C7E3CE77%2EBD0EBCE24FE9A3C5%2E4D4702B0C3E38B35%2E4D4702B0C3E38B35&amp;__acm__=1575108223_4c676709117010e6d07bffafb2c8e6c5#BibPLXBIB0018" data-original-title="" title="" id="auto-BibPLXBIB001833">18</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="http://delivery.acm.org/10.1145/3310000/3300233/a3-amershi.html?ip=169.237.6.227&amp;id=3300233&amp;acc=ACTIVE%20SERVICE&amp;key=CA367851C7E3CE77%2EBD0EBCE24FE9A3C5%2E4D4702B0C3E38B35%2E4D4702B0C3E38B35&amp;__acm__=1575108223_4c676709117010e6d07bffafb2c8e6c5#BibPLXBIB0033" data-original-title="" title="" id="auto-BibPLXBIB003334">33</a>]). This scenario has also had a recent resurgence of interest given advances in natural language processing and embedded devices driving the proliferation of conversational agents [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="http://delivery.acm.org/10.1145/3310000/3300233/a3-amershi.html?ip=169.237.6.227&amp;id=3300233&amp;acc=ACTIVE%20SERVICE&amp;key=CA367851C7E3CE77%2EBD0EBCE24FE9A3C5%2E4D4702B0C3E38B35%2E4D4702B0C3E38B35&amp;__acm__=1575108223_4c676709117010e6d07bffafb2c8e6c5#BibPLXBIB0026" data-original-title="" title="" id="auto-BibPLXBIB002635">26</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="http://delivery.acm.org/10.1145/3310000/3300233/a3-amershi.html?ip=169.237.6.227&amp;id=3300233&amp;acc=ACTIVE%20SERVICE&amp;key=CA367851C7E3CE77%2EBD0EBCE24FE9A3C5%2E4D4702B0C3E38B35%2E4D4702B0C3E38B35&amp;__acm__=1575108223_4c676709117010e6d07bffafb2c8e6c5#BibPLXBIB0029" data-original-title="" title="" id="auto-BibPLXBIB002936">29</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="http://delivery.acm.org/10.1145/3310000/3300233/a3-amershi.html?ip=169.237.6.227&amp;id=3300233&amp;acc=ACTIVE%20SERVICE&amp;key=CA367851C7E3CE77%2EBD0EBCE24FE9A3C5%2E4D4702B0C3E38B35%2E4D4702B0C3E38B35&amp;__acm__=1575108223_4c676709117010e6d07bffafb2c8e6c5#BibPLXBIB0035" data-original-title="" title="" id="auto-BibPLXBIB003537">35</a>]. Similarly, researchers have for decades studied human interaction with intelligent context-aware computing systems including how to design for understandability and control of the underlying sensing systems [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="http://delivery.acm.org/10.1145/3310000/3300233/a3-amershi.html?ip=169.237.6.227&amp;id=3300233&amp;acc=ACTIVE%20SERVICE&amp;key=CA367851C7E3CE77%2EBD0EBCE24FE9A3C5%2E4D4702B0C3E38B35%2E4D4702B0C3E38B35&amp;__acm__=1575108223_4c676709117010e6d07bffafb2c8e6c5#BibPLXBIB0003" data-original-title="" title="" id="auto-BibPLXBIB000338">3</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="http://delivery.acm.org/10.1145/3310000/3300233/a3-amershi.html?ip=169.237.6.227&amp;id=3300233&amp;acc=ACTIVE%20SERVICE&amp;key=CA367851C7E3CE77%2EBD0EBCE24FE9A3C5%2E4D4702B0C3E38B35%2E4D4702B0C3E38B35&amp;__acm__=1575108223_4c676709117010e6d07bffafb2c8e6c5#BibPLXBIB0023" data-original-title="" title="" id="auto-BibPLXBIB002339">23</a>] and how to support ambiguity resolution [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="http://delivery.acm.org/10.1145/3310000/3300233/a3-amershi.html?ip=169.237.6.227&amp;id=3300233&amp;acc=ACTIVE%20SERVICE&amp;key=CA367851C7E3CE77%2EBD0EBCE24FE9A3C5%2E4D4702B0C3E38B35%2E4D4702B0C3E38B35&amp;__acm__=1575108223_4c676709117010e6d07bffafb2c8e6c5#BibPLXBIB0010" data-original-title="" title="" id="auto-BibPLXBIB001040">10</a>]. Recent advances in sensing technologies and the widespread availability of commercial fitness and activity trackers have continued to drive interaction research in these domains [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="http://delivery.acm.org/10.1145/3310000/3300233/a3-amershi.html?ip=169.237.6.227&amp;id=3300233&amp;acc=ACTIVE%20SERVICE&amp;key=CA367851C7E3CE77%2EBD0EBCE24FE9A3C5%2E4D4702B0C3E38B35%2E4D4702B0C3E38B35&amp;__acm__=1575108223_4c676709117010e6d07bffafb2c8e6c5#BibPLXBIB0037" data-original-title="" title="" id="auto-BibPLXBIB003741">37</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="http://delivery.acm.org/10.1145/3310000/3300233/a3-amershi.html?ip=169.237.6.227&amp;id=3300233&amp;acc=ACTIVE%20SERVICE&amp;key=CA367851C7E3CE77%2EBD0EBCE24FE9A3C5%2E4D4702B0C3E38B35%2E4D4702B0C3E38B35&amp;__acm__=1575108223_4c676709117010e6d07bffafb2c8e6c5#BibPLXBIB0045" data-original-title="" title="" id="auto-BibPLXBIB004542">45</a>].</p> <p>Despite all of this work, the ongoing stream of articles and editorials in the public domain about how to design in the face of AI (e.g., [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="http://delivery.acm.org/10.1145/3310000/3300233/a3-amershi.html?ip=169.237.6.227&amp;id=3300233&amp;acc=ACTIVE%20SERVICE&amp;key=CA367851C7E3CE77%2EBD0EBCE24FE9A3C5%2E4D4702B0C3E38B35%2E4D4702B0C3E38B35&amp;__acm__=1575108223_4c676709117010e6d07bffafb2c8e6c5#BibPLXBIB0002" data-original-title="" title="" id="auto-BibPLXBIB000243">2</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="http://delivery.acm.org/10.1145/3310000/3300233/a3-amershi.html?ip=169.237.6.227&amp;id=3300233&amp;acc=ACTIVE%20SERVICE&amp;key=CA367851C7E3CE77%2EBD0EBCE24FE9A3C5%2E4D4702B0C3E38B35%2E4D4702B0C3E38B35&amp;__acm__=1575108223_4c676709117010e6d07bffafb2c8e6c5#BibPLXBIB0024" data-original-title="" title="" id="auto-BibPLXBIB002444">24</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="http://delivery.acm.org/10.1145/3310000/3300233/a3-amershi.html?ip=169.237.6.227&amp;id=3300233&amp;acc=ACTIVE%20SERVICE&amp;key=CA367851C7E3CE77%2EBD0EBCE24FE9A3C5%2E4D4702B0C3E38B35%2E4D4702B0C3E38B35&amp;__acm__=1575108223_4c676709117010e6d07bffafb2c8e6c5#BibPLXBIB0025" data-original-title="" title="" id="auto-BibPLXBIB002545">25</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="http://delivery.acm.org/10.1145/3310000/3300233/a3-amershi.html?ip=169.237.6.227&amp;id=3300233&amp;acc=ACTIVE%20SERVICE&amp;key=CA367851C7E3CE77%2EBD0EBCE24FE9A3C5%2E4D4702B0C3E38B35%2E4D4702B0C3E38B35&amp;__acm__=1575108223_4c676709117010e6d07bffafb2c8e6c5#BibPLXBIB0039" data-original-title="" title="" id="auto-BibPLXBIB003946">39</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="http://delivery.acm.org/10.1145/3310000/3300233/a3-amershi.html?ip=169.237.6.227&amp;id=3300233&amp;acc=ACTIVE%20SERVICE&amp;key=CA367851C7E3CE77%2EBD0EBCE24FE9A3C5%2E4D4702B0C3E38B35%2E4D4702B0C3E38B35&amp;__acm__=1575108223_4c676709117010e6d07bffafb2c8e6c5#BibPLXBIB0042" data-original-title="" title="" id="auto-BibPLXBIB004247">42</a>]) suggests designers need more guidance. This may be partly due to design suggestions being scattered throughout different academic circles and venues, making them difficult to find (e.g., there is relevant work in a wide variety of venues including AAAI, UbiComp, RecSys, SIGIR, HRI, KDD). Moreover, potential design suggestions for AI are often not presented explicitly as such. In many cases, researchers identify usability issues with AI systems and suggest possible solutions in the discussion or future work sections of their academic papers. For example, Lugar and Sellen [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="http://delivery.acm.org/10.1145/3310000/3300233/a3-amershi.html?ip=169.237.6.227&amp;id=3300233&amp;acc=ACTIVE%20SERVICE&amp;key=CA367851C7E3CE77%2EBD0EBCE24FE9A3C5%2E4D4702B0C3E38B35%2E4D4702B0C3E38B35&amp;__acm__=1575108223_4c676709117010e6d07bffafb2c8e6c5#BibPLXBIB0026" data-original-title="" title="" id="auto-BibPLXBIB002648">26</a>] identify variability in user expectations of conversational agents as causing usability issues and propose setting realistic expectations as a possible solution in their discussion. Similarly, Lee et al [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="http://delivery.acm.org/10.1145/3310000/3300233/a3-amershi.html?ip=169.237.6.227&amp;id=3300233&amp;acc=ACTIVE%20SERVICE&amp;key=CA367851C7E3CE77%2EBD0EBCE24FE9A3C5%2E4D4702B0C3E38B35%2E4D4702B0C3E38B35&amp;__acm__=1575108223_4c676709117010e6d07bffafb2c8e6c5#BibPLXBIB0022" data-original-title="" title="" id="auto-BibPLXBIB002249">22</a>] studied automatic changes to search result lists during user interaction and suggested caution in updating those lists to balance stability with presenting new content to users. While these proposed solutions could be generalized into principles for designers, not presenting them as such makes them difficult to discover.</p> <p>It can also be difficult to understand if and how design guidance stemming from one community or interaction scenario extends to others. For example, Bunt et al. [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="http://delivery.acm.org/10.1145/3310000/3300233/a3-amershi.html?ip=169.237.6.227&amp;id=3300233&amp;acc=ACTIVE%20SERVICE&amp;key=CA367851C7E3CE77%2EBD0EBCE24FE9A3C5%2E4D4702B0C3E38B35%2E4D4702B0C3E38B35&amp;__acm__=1575108223_4c676709117010e6d07bffafb2c8e6c5#BibPLXBIB0004" data-original-title="" title="" id="auto-BibPLXBIB000450">4</a>] showed that, while explanations of AI behaviors have shown promise in complex and high-risk scenarios such as sensor-based ubiquitous computing systems or decision-support systems for medical or financial domains, they may be less important for relatively low-cost scenarios such as search and music or movie recommenders.</p> <p>In this work we 1) synthesize a unified set of design guidelines from a variety of communities and sources and 2) systematically examine those guidelines in a variety of AI-infused systems to validate their applicability and relevance. The closest to our work is Horvitz's set of principles for mixed-initiative systems [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="http://delivery.acm.org/10.1145/3310000/3300233/a3-amershi.html?ip=169.237.6.227&amp;id=3300233&amp;acc=ACTIVE%20SERVICE&amp;key=CA367851C7E3CE77%2EBD0EBCE24FE9A3C5%2E4D4702B0C3E38B35%2E4D4702B0C3E38B35&amp;__acm__=1575108223_4c676709117010e6d07bffafb2c8e6c5#BibPLXBIB0017" data-original-title="" title="" id="auto-BibPLXBIB001751">17</a>], noting that 8 of our 18 guidelines map to principles outlined in that work. We celebrate its 20-year anniversary by reflecting on learnings from the community since its publication. Moreover, recent work has warned that the lack of rigorous validations of proposed design heuristics in specific domains makes it difficult to gauge the utility of those heuristics [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="http://delivery.acm.org/10.1145/3310000/3300233/a3-amershi.html?ip=169.237.6.227&amp;id=3300233&amp;acc=ACTIVE%20SERVICE&amp;key=CA367851C7E3CE77%2EBD0EBCE24FE9A3C5%2E4D4702B0C3E38B35%2E4D4702B0C3E38B35&amp;__acm__=1575108223_4c676709117010e6d07bffafb2c8e6c5#BibPLXBIB0015" data-original-title="" title="" id="auto-BibPLXBIB001552">15</a>]. We developed the guidelines shown in Table <a class="tbl" href="http://delivery.acm.org/10.1145/3310000/3300233/a3-amershi.html?ip=169.237.6.227&amp;id=3300233&amp;acc=ACTIVE%20SERVICE&amp;key=CA367851C7E3CE77%2EBD0EBCE24FE9A3C5%2E4D4702B0C3E38B35%2E4D4702B0C3E38B35&amp;__acm__=1575108223_4c676709117010e6d07bffafb2c8e6c5#tab1">1</a> using a four-phase process. In Phase 1 we consolidated more than 150 design recommendations from multiple sources into a set of 20 guidelines. In Phase 2 we conducted an internal modified heuristic evaluation of the guidelines, revising the set down to 18. Phase 3 consisted of a user study in which 49 participants used heuristic evaluation to assess the guidelines’ relevance and clarity. Based on their feedback, we rephrased some of the guidelines to improve clarity and, in Phase 4, conducted an expert evaluation of the revisions to validate the final set.</p> </section> <section id="sec-4"> <header> <div class="title-info"> <h2> <span class="section-number"><span class="nav-open" id="nav-open" onclick="openNav(this)" title="navigate to" tabindex="0">3</span></span> PHASE 1: CONSOLIDATING GUIDELINES</h2> </div> </header> <p>We gathered AI design recommendations from three sources:</p> <ul class="list-no-style"> <li id="list3" label="•">A review of AI products and guidelines originating from industry. We collected guidelines asserted internally in our company and externally, and grouped them into themes; we audited a sample of AI products within and outside our company against the themes; and cross-referenced themes with internal customer feedback (reviews and bugs reported about our company's AI products).<br></li> <li id="list4" label="•">Recent public articles and editorials about AI design (e.g., [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="http://delivery.acm.org/10.1145/3310000/3300233/a3-amershi.html?ip=169.237.6.227&amp;id=3300233&amp;acc=ACTIVE%20SERVICE&amp;key=CA367851C7E3CE77%2EBD0EBCE24FE9A3C5%2E4D4702B0C3E38B35%2E4D4702B0C3E38B35&amp;__acm__=1575108223_4c676709117010e6d07bffafb2c8e6c5#BibPLXBIB0002" data-original-title="" title="" id="auto-BibPLXBIB000253">2</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="http://delivery.acm.org/10.1145/3310000/3300233/a3-amershi.html?ip=169.237.6.227&amp;id=3300233&amp;acc=ACTIVE%20SERVICE&amp;key=CA367851C7E3CE77%2EBD0EBCE24FE9A3C5%2E4D4702B0C3E38B35%2E4D4702B0C3E38B35&amp;__acm__=1575108223_4c676709117010e6d07bffafb2c8e6c5#BibPLXBIB0024" data-original-title="" title="" id="auto-BibPLXBIB002454">24</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="http://delivery.acm.org/10.1145/3310000/3300233/a3-amershi.html?ip=169.237.6.227&amp;id=3300233&amp;acc=ACTIVE%20SERVICE&amp;key=CA367851C7E3CE77%2EBD0EBCE24FE9A3C5%2E4D4702B0C3E38B35%2E4D4702B0C3E38B35&amp;__acm__=1575108223_4c676709117010e6d07bffafb2c8e6c5#BibPLXBIB0025" data-original-title="" title="" id="auto-BibPLXBIB002555">25</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="http://delivery.acm.org/10.1145/3310000/3300233/a3-amershi.html?ip=169.237.6.227&amp;id=3300233&amp;acc=ACTIVE%20SERVICE&amp;key=CA367851C7E3CE77%2EBD0EBCE24FE9A3C5%2E4D4702B0C3E38B35%2E4D4702B0C3E38B35&amp;__acm__=1575108223_4c676709117010e6d07bffafb2c8e6c5#BibPLXBIB0039" data-original-title="" title="" id="auto-BibPLXBIB003956">39</a>]).<br></li> <li id="list5" label="•">Relevant scholarly papers about AI design (see Related Work section).<br></li> </ul> <p>While we drew AI design guidelines from the academic literature, the list we captured may not be exhaustive because, as discussed in Related Work, potential design guidelines are often not presented explicitly as such, making them difficult to search for via terms or combinations of terms such as “AI”, “machine learning”, “design”, “principle” or “guideline”. Further, as the field is evolving rapidly, we found the most up to date guidance about AI design in industry sources via articles published in the public domain.</p> <p>From these sources, we obtained 168 potential AI design guidelines. Three members of our team conducted an asynchronous affinity diagramming process, clustering the guidelines into related concepts. This resulted in 35 concepts which we then filtered by removing concepts we deemed to be either too vague to design for directly (e.g., “build trust”), too specific to a particular AI scenario (e.g., “establish that the bot is not human”), or not AI specific (e.g., “display output effectively”). Filtering reduced our set of concepts to 20, each of which we then summarized in a sentence or phrase, forming our first iteration of the guidelines. We organized the guidelines into four top-level categories based on when during the user's interaction they applied: “Initially” (Guideline 1 &amp; Guideline 2), “During interaction” (Guideline 3 - Guideline 6), “When wrong” (Guideline 7 - Guideline 11), and “Over time” (Guideline 12 - Guideline 18). Next, we tested the guidelines via a modified heuristic evaluation.</p> </section> <section id="sec-5"> <header> <div class="title-info"> <h2> <span class="section-number"><span class="nav-open" id="nav-open" onclick="openNav(this)" title="navigate to" tabindex="0">4</span></span> PHASE 2: MODIFIED HEURISTIC EVALUATION</h2> </div> </header> <p>We conducted an evaluation to test and iterate on the initial set of 20 AI design guidelines. We modeled our study after a heuristic evaluation [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="http://delivery.acm.org/10.1145/3310000/3300233/a3-amershi.html?ip=169.237.6.227&amp;id=3300233&amp;acc=ACTIVE%20SERVICE&amp;key=CA367851C7E3CE77%2EBD0EBCE24FE9A3C5%2E4D4702B0C3E38B35%2E4D4702B0C3E38B35&amp;__acm__=1575108223_4c676709117010e6d07bffafb2c8e6c5#BibPLXBIB0031" data-original-title="" title="" id="auto-BibPLXBIB003157">31</a>], a common discount usability testing method where evaluators examine an interface for violations of a given set of usability guidelines. As the primary goal was to evaluate our design guidelines rather than to evaluate an interface, we modified the heuristic evaluation by asking evaluators to attempt to identify both applications and violations of the proposed guidelines in an interface and to reflect on the guidelines themselves during the evaluation.</p> <p>Eleven members of our team participated in this evaluation. Team members selected AI-infused products or features of their choice and then looked for applications or violations of our initial set of design guidelines over a one-hour period. In total, we inspected 13 AI-infused products or features including: two different email products with a feature for filtering unimportant emails, a navigation system, an e-commerce website with product recommendations, two photo organization products, a design assistance feature in a productivity software, a research assistance feature in a productivity application, a social network news feed feature, a web search service, and an image search service. These products were different from the products used in Phase 3.</p> <p>After the modified heuristic evaluation, we reviewed the findings and reflections about each guideline and discussed issues and revision strategies for conflicting interpretations and ambiguities. For example, our initial phrasing of Guideline 9 (“allow efficient correction”) and Guideline 17 (“allow coarse controls”) caused several evaluators to confuse instance-level corrections with global-level settings (several evaluators identified adjusting settings as applications of Guideline 9 rather than Guideline 17). We subsequently rephrased Guideline 17 to include the term “global”.</p> <p>We also identified opportunities for merging related or redundant guidelines. For example, the initial set included “informing the user when to take control” and “fallback to a human where appropriate”. Our evaluations found few applications of these guidelines, and we determined both of them to be instances of Guideline 10 (initially phrased “scope services when uncertain”) and therefore removed them as distinct guidelines. Similarly, applications of “enable users to change privacy permissions” and “allow private mode” were deemed as instances of Guideline 17 (initially phrased “allow coarse controls”) and were merged with that guideline.</p> <p>We also decided to remove some guidelines that resulted in few or no applications during our evaluations. For example, neither the guideline to “explore vs. exploit in moderation” nor to “be especially conservative in the beginning” resulted in any identifiable usage across the products or features we examined. While these guidelines are important at the AI modeling level, they appeared to be difficult to observe or design for in an interface.</p> <p>After these sessions we reformulated the remaining guidelines to follow a consistent format and to clarify issues identified by evaluators. Specifically, we proposed that each guideline adhere to the following criteria:</p> <ul class="list-no-style"> <li id="list6" label="•">It should be written as a rule of action, containing about 3-10 words and starting with a verb.<br></li> <li id="list7" label="•">It should be accompanied by a one-sentence description that qualifies or clarifies any potential ambiguities.<br></li> <li id="list8" label="•">It should not contain conjunctions so that designers can clearly validate whether it is applied or violated in an interface.<br></li> </ul> <p>Removing conjunctions meant splitting some guidelines. For example, an initial guideline to “allow efficient invocation, correction, and dismissal” became three (to “support efficient invocation,” “support efficient dismissal,” and “support efficient correction,” Guidelines 7-9).</p> <p>Phase 2 produced a set of 18 guidelines that closely match the guidelines in Table <a class="tbl" href="http://delivery.acm.org/10.1145/3310000/3300233/a3-amershi.html?ip=169.237.6.227&amp;id=3300233&amp;acc=ACTIVE%20SERVICE&amp;key=CA367851C7E3CE77%2EBD0EBCE24FE9A3C5%2E4D4702B0C3E38B35%2E4D4702B0C3E38B35&amp;__acm__=1575108223_4c676709117010e6d07bffafb2c8e6c5#tab1">1</a>. In the following sections we describe a user study that tested these 18 guidelines and a subsequent expert validation of the guidelines that we slightly rephrased after the user study (resulting in the final proposed set shown in Table <a class="tbl" href="http://delivery.acm.org/10.1145/3310000/3300233/a3-amershi.html?ip=169.237.6.227&amp;id=3300233&amp;acc=ACTIVE%20SERVICE&amp;key=CA367851C7E3CE77%2EBD0EBCE24FE9A3C5%2E4D4702B0C3E38B35%2E4D4702B0C3E38B35&amp;__acm__=1575108223_4c676709117010e6d07bffafb2c8e6c5#tab1">1</a>).</p> </section> <section id="sec-6"> <header> <div class="title-info"> <h2> <span class="section-number"><span class="nav-open" id="nav-open" onclick="openNav(this)" title="navigate to" tabindex="0">5</span></span> PHASE 3: USER STUDY</h2> </div> </header> <p>We conducted a user study with 49 HCI practitioners to 1)&nbsp;understand the guidelines’ applicability across a variety of products; and 2) get feedback about the guidelines’ clarity.</p> <section id="sec-7"> <header> <div class="title-info"> <h3> <span class="section-number"><span class="nav-open" id="nav-open" onclick="openNav(this)" title="navigate to" tabindex="0"> </span></span> Procedure</h3> </div> </header> <p>We modeled the user study after a heuristic evaluation. We assigned each participant to an AI-driven feature of a product they were familiar with and asked them to find examples (applications and violations) of each guideline.</p> <p>First, we helped participants become familiar with the guidelines by providing a document that included at least one application and one violation for each. The examples came from a range of AI-infused products and were presented with a 1-2 sentence description and a screenshot where appropriate.</p> <p>Participants were then instructed to play around with their assigned feature and fill out a form asking a series of questions. For each guideline, the form asked participants to first determine if the guideline “does not apply” to their assigned feature (i.e., irrelevant or out of scope) and, if not, to explain why. If a participant judged that a guideline should apply to their assigned feature and they observed applications or violations, the form requested participants to provide their own examples, and, for each example, a rating of the extent of the application or violation on a 5-point semantic differential scale from “clearly violated” to “clearly applied”, along with an explanation of the rating. Participants were incentivized with an additional monetary gratuity to include screenshots to illustrate the examples. After completing the evaluation, participants submitted their examples and ratings and filled in a final questionnaire which asked them to rate each guideline on a 5-point semantic differential scale from “very confusing” to “very clear” and provide any additional comments about the guidelines.</p> <p>We estimated the study would take approximately one hour to complete based on our modified heuristic evaluation study from Phase 2. Participants were given one week to complete the study on their own time and were compensated with an Amazon Gift Card worth a minimum of <font style="normal">$</font>50 and up to <font style="normal">$</font>70 based on the number of applications or violations for which they provided screenshots.</p> </section> <section id="sec-8"> <header> <div class="title-info"> <h3> <span class="section-number"><span class="nav-open" id="nav-open" onclick="openNav(this)" title="navigate to" tabindex="0"> </span></span> Products</h3> </div> </header> <p>One objective of our study was to determine if and how each of our design guidelines manifests in a variety of AI-infused products. We used a maximum-variance sampling strategy [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="http://delivery.acm.org/10.1145/3310000/3300233/a3-amershi.html?ip=169.237.6.227&amp;id=3300233&amp;acc=ACTIVE%20SERVICE&amp;key=CA367851C7E3CE77%2EBD0EBCE24FE9A3C5%2E4D4702B0C3E38B35%2E4D4702B0C3E38B35&amp;__acm__=1575108223_4c676709117010e6d07bffafb2c8e6c5#BibPLXBIB0028" data-original-title="" title="" id="auto-BibPLXBIB002858">28</a>] to select popular AI-infused products that covered a wide range of scenarios.</p> <p>First, we searched online for rankings of top apps, software, and websites in the U.S. for both mobile and desktop devices. This search resulted in 13 lists from sources such as app stores (Apple, Google Play, Windows), and Web traffic rankings [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="http://delivery.acm.org/10.1145/3310000/3300233/a3-amershi.html?ip=169.237.6.227&amp;id=3300233&amp;acc=ACTIVE%20SERVICE&amp;key=CA367851C7E3CE77%2EBD0EBCE24FE9A3C5%2E4D4702B0C3E38B35%2E4D4702B0C3E38B35&amp;__acm__=1575108223_4c676709117010e6d07bffafb2c8e6c5#BibPLXBIB0001" data-original-title="" title="" id="auto-BibPLXBIB000159">1</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="http://delivery.acm.org/10.1145/3310000/3300233/a3-amershi.html?ip=169.237.6.227&amp;id=3300233&amp;acc=ACTIVE%20SERVICE&amp;key=CA367851C7E3CE77%2EBD0EBCE24FE9A3C5%2E4D4702B0C3E38B35%2E4D4702B0C3E38B35&amp;__acm__=1575108223_4c676709117010e6d07bffafb2c8e6c5#BibPLXBIB0006" data-original-title="" title="" id="auto-BibPLXBIB000660">6</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="http://delivery.acm.org/10.1145/3310000/3300233/a3-amershi.html?ip=169.237.6.227&amp;id=3300233&amp;acc=ACTIVE%20SERVICE&amp;key=CA367851C7E3CE77%2EBD0EBCE24FE9A3C5%2E4D4702B0C3E38B35%2E4D4702B0C3E38B35&amp;__acm__=1575108223_4c676709117010e6d07bffafb2c8e6c5#BibPLXBIB0040" data-original-title="" title="" id="auto-BibPLXBIB004061">40</a>]. From these lists, we selected the top 10 products in each and then filtered out any that were offensive, game related, or did not currently use AI to drive any of their main end-user facing services (determined by examination of the product or reading supplemental help documentation and news media articles when necessary).</p> <p>Next, we grouped the remaining products by their primary use case, resulting in 10 categories (e.g., email, e-commerce, social networking). We then selected two products per category based on market share as determined by recent online statistics reports (e.g., [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="http://delivery.acm.org/10.1145/3310000/3300233/a3-amershi.html?ip=169.237.6.227&amp;id=3300233&amp;acc=ACTIVE%20SERVICE&amp;key=CA367851C7E3CE77%2EBD0EBCE24FE9A3C5%2E4D4702B0C3E38B35%2E4D4702B0C3E38B35&amp;__acm__=1575108223_4c676709117010e6d07bffafb2c8e6c5#BibPLXBIB0019" data-original-title="" title="" id="auto-BibPLXBIB001962">19</a>]). Finally, we selected a prominent AI-driven feature to evaluate per product. In total, we selected 20 products, two of which were from Microsoft.</p> <p>Many of the products we selected were available on multiple platforms and devices. We attempted to evaluate products on a variety of platforms. Table&nbsp;<a class="tbl" href="http://delivery.acm.org/10.1145/3310000/3300233/a3-amershi.html?ip=169.237.6.227&amp;id=3300233&amp;acc=ACTIVE%20SERVICE&amp;key=CA367851C7E3CE77%2EBD0EBCE24FE9A3C5%2E4D4702B0C3E38B35%2E4D4702B0C3E38B35&amp;__acm__=1575108223_4c676709117010e6d07bffafb2c8e6c5#tab2">2</a> shows our final list of product categories, features and platforms.</p> </section> <section id="sec-9"> <header> <div class="title-info"> <h3> <span class="section-number"><span class="nav-open" id="nav-open" onclick="openNav(this)" title="navigate to" tabindex="0"> </span></span> Participants</h3> </div> </header> <p>We recruited participants via HCI and design distribution lists at a large software company. During recruitment we screened for people with at least one year of experience working in or studying HCI (e.g., in roles such as user experience design and user experience research) and familiarity with discount usability testing methods (e.g., heuristic evaluation, cognitive walkthrough). We listed all possible product and platform combinations, and asked respondents to select the options they were familiar with and comfortable evaluating.</p> <p>We endeavored to assign 2-3 participants to each product according to recommendations for heuristic evaluations. Nielsen [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="http://delivery.acm.org/10.1145/3310000/3300233/a3-amershi.html?ip=169.237.6.227&amp;id=3300233&amp;acc=ACTIVE%20SERVICE&amp;key=CA367851C7E3CE77%2EBD0EBCE24FE9A3C5%2E4D4702B0C3E38B35%2E4D4702B0C3E38B35&amp;__acm__=1575108223_4c676709117010e6d07bffafb2c8e6c5#BibPLXBIB0030" data-original-title="" title="" id="auto-BibPLXBIB003063">30</a>] recommends 2-3 evaluators when evaluators have both usability experience and familiarity with the product being tested. We also assigned participants so that each product was evaluated by people with a range of experience in discount usability techniques and no product was evaluated by participants with only limited experience. When participants dropped out of the study, we replaced them by assigning new participants from a wait list of eligible respondents, trying to maintain 2-3 evaluators per product.</p> <p>In the end, 49 people (29 female, 18 male, 2 preferred not to answer) participated in our study. Participants spanned ages 18-55: 5 were in the age range of 18-24, 24 were in the age range of 25-34, 13 were aged 35-44 and 7 were aged 45-54. Of these participants, 19 were researchers, 12 were designers, 11 were HCI or design interns from various universities worldwide, and the remaining 7 were a mix of engineers, product managers or vendors. The participants’ experience working in or studying HCI/UX was as follows: 1-4 years (23 participants), 5-9 years (14 participants), 10-14 years (9 participants), 15-19 years (1 participant), 20+ years (2 participants). Thirty-nine participants self-reported as being highly or very highly experienced at discount usability testing methods while 10 reported as having medium to low levels of experience (we screened out participants with “very low” levels of experience). Participants were from 4 different countries spanning 3 continents. While we recruited participants using internal mailing lists, we took steps to mitigate sampling bias to ensure the results do not exclusively represent one organization's mindset, in addition to including the 11 external participants. Our questionnaires asked participants to rate the extent to which an example is illustrative of a guideline and the clarity of each guideline's wording on Likert scales. These questions are unlikely to be influenced by company values. Moreover, our main sampling criterion was experience with discount usability methods. It is unlikely that the entirety of participants’ professional training and experience were internal.</p> <div class="table-responsive" id="tab2"> <div class="table-caption"> <span class="table-number">Table 2:</span> <span class="table-title">Product categories and features tested in the user study, and the number of participants assigned to each.</span> </div> <table class="table"> <thead> <tr> <th style="text-align:center;border-right: 2pt solid #000000;"><strong>Product Category</strong></th> <th style="text-align:center;border-right: 2pt solid #000000;"><strong>Feature</strong></th> <th style="text-align:center;border-right: 2pt solid #000000;"><strong>Participants</strong></th> </tr> </thead> <tbody> <tr> <td style="text-align:center;border-right: 2pt solid #000000;">E-commerce (Web)</td> <td style="text-align:center;border-right: 2pt solid #000000;">Recommendations</td> <td style="text-align:center;border-right: 2pt solid #000000;">6</td> </tr> <tr> <td style="text-align:center;border-right: 2pt solid #000000;">Navigation (Mobile)</td> <td style="text-align:center;border-right: 2pt solid #000000;">Route planning</td> <td style="text-align:center;border-right: 2pt solid #000000;">5</td> </tr> <tr> <td style="text-align:center;border-right: 2pt solid #000000;">Music Recommenders (Mobile)</td> <td style="text-align:center;border-right: 2pt solid #000000;">Recommendations</td> <td style="text-align:center;border-right: 2pt solid #000000;">5</td> </tr> <tr> <td style="text-align:center;border-right: 2pt solid #000000;">Activity Trackers (Device)</td> <td style="text-align:center;border-right: 2pt solid #000000;">Walking detection and step count</td> <td style="text-align:center;border-right: 2pt solid #000000;">5</td> </tr> <tr> <td style="text-align:center;border-right: 2pt solid #000000;">Autocomplete (Mobile)</td> <td style="text-align:center;border-right: 2pt solid #000000;">Autocomplete</td> <td style="text-align:center;border-right: 2pt solid #000000;">5</td> </tr> <tr> <td style="text-align:center;border-right: 2pt solid #000000;">Social Networks (Mobile)</td> <td style="text-align:center;border-right: 2pt solid #000000;">Feed filtering</td> <td style="text-align:center;border-right: 2pt solid #000000;">5</td> </tr> <tr> <td style="text-align:center;border-right: 2pt solid #000000;">Email (Web)</td> <td style="text-align:center;border-right: 2pt solid #000000;">Importance filtering</td> <td style="text-align:center;border-right: 2pt solid #000000;">5</td> </tr> <tr> <td style="text-align:center;border-right: 2pt solid #000000;">Voice Assistants (Device)</td> <td style="text-align:center;border-right: 2pt solid #000000;">Creating a reminder with a due date</td> <td style="text-align:center;border-right: 2pt solid #000000;">5</td> </tr> <tr> <td style="text-align:center;border-right: 2pt solid #000000;">Photo Organizers (Mobile)</td> <td style="text-align:center;border-right: 2pt solid #000000;">Album suggestions</td> <td style="text-align:center;border-right: 2pt solid #000000;">4</td> </tr> <tr> <td style="text-align:center;border-right: 2pt solid #000000;">Web Search (Web)</td> <td style="text-align:center;border-right: 2pt solid #000000;">Search</td> <td style="text-align:center;border-right: 2pt solid #000000;">4</td> </tr> </tbody> </table> </div> </section> <section id="sec-10"> <header> <div class="title-info"> <h3> <span class="section-number"><span class="nav-open" id="nav-open" onclick="openNav(this)" title="navigate to" tabindex="0"> </span></span> Adjustments and Misinterpretations</h3> </div> </header> <p>To obtain accurate counts of examples of the proposed guidelines across products, we reviewed participant responses for the following cases:</p> <ul class="list-no-style"> <li id="list9" label="•">Duplicate applications or violations of a guideline for any given product (55 instances). For example, two different participants identified the same application of Guideline 1 for an activity tracker: “This guideline is applied in the activity summary view, where it shows a summary of my ‘move’, ‘exercise’ and ‘stand’ metrics.” and “Displays all the metrics that it tracks and explains how. Metrics include movement metrics such as steps, distance traveled...” The 55 duplications were removed from the analysis.<br></li> <li id="list10" label="•">Instances where participants used “does not apply” to indicate that they could not find examples of a guideline rather than to indicate that the guideline is not relevant for the product they were testing, as we intended by this designation (73 instances). For example, “To be quite honest I believe that this would apply, however I can't think of a way to show it.” and “Cannot find examples of application or violation.”. These 73 instances were also removed from the analysis.<br></li> <li id="list11" label="•">Instances where participants used “does not apply” to indicate that a guideline was violated (20 instances). For example, “Even in the setting page, there's no option for changing or customizing anything for the autocomplete function.” and “[Voice Assistant, Product #1] did not provide additional hints or tips to educate me on what the system is capable of achieving beyond the task I had already asked it to run.” We reclassified these instances as violations.<br></li> <li id="list12" label="•">Instances where participants misinterpreted one guideline for another, discussed further below (56 instances).<br></li> </ul> <p>We identified these cases using a two-pass process where participant responses were first reviewed by one member of our team to identify each case and then those cases were verified or invalidated by another member of our team. We removed 14 additional instances from our analysis when the two reviewers from our team disagreed on any of these cases.</p> </section> <section id="sec-11"> <header> <div class="title-info"> <h3> <span class="section-number"><span class="nav-open" id="nav-open" onclick="openNav(this)" title="navigate to" tabindex="0"> </span></span> Results</h3> </div> </header> <p>Our evaluation in this phase focused on two key questions, each addressed in one of the subsections below: 1) Are the guidelines relevant? That is, can we identify examples of each guideline across a variety of products and features? 2) Are the guidelines clear? That is, can participants understand and differentiate among them? </p><figure id="fig1"> <img src="./paper-chi-algorithm-3_files/chi2019-3-fig1.jpg" class="img-responsive" alt="" longdesc="(Top Left). Summary of the number of applications of each human-AI interaction guideline detected during user testing per AI product category. (Top Right). Summary of the number of violations of each human-AI interaction guideline detected during user testing per AI product category. (Bottom Left). Summary of the number of “does not apply” responses from user testing participants for each human-AI interaction guideline per AI product category. (Bottom Right). Summary of the total number of responses from user testing participants for each human-AI interaction guideline per AI product category."> <div class="figure-caption"> <span class="figure-number">Figure 1:</span> <span class="figure-title">Counts of applications (top left), violations (top right), and “does not apply” (bottom left) responses in our user study. Rows show counts by guideline, while columns show counts by product category tested.</span> </div> </figure> <p></p> <section id="sec-12"> <p><em> Relevance.</em> Across the 20 products they evaluated, participants identified 785 examples of the 18 guidelines, after the adjustments described earlier: 313 applications, 277 violations, 89 neutrals (rated at the mid-point between “clearly applied” and “clearly violated”), and 106 instances of “does not apply”. Figures <a class="fig" href="http://delivery.acm.org/10.1145/3310000/3300233/a3-amershi.html?ip=169.237.6.227&amp;id=3300233&amp;acc=ACTIVE%20SERVICE&amp;key=CA367851C7E3CE77%2EBD0EBCE24FE9A3C5%2E4D4702B0C3E38B35%2E4D4702B0C3E38B35&amp;__acm__=1575108223_4c676709117010e6d07bffafb2c8e6c5#fig1">1</a> a-<a class="fig" href="http://delivery.acm.org/10.1145/3310000/3300233/a3-amershi.html?ip=169.237.6.227&amp;id=3300233&amp;acc=ACTIVE%20SERVICE&amp;key=CA367851C7E3CE77%2EBD0EBCE24FE9A3C5%2E4D4702B0C3E38B35%2E4D4702B0C3E38B35&amp;__acm__=1575108223_4c676709117010e6d07bffafb2c8e6c5#fig1">1</a> c show the guideline counts per product category for applications, violations, and “does not apply”, respectively. Figure <a class="fig" href="http://delivery.acm.org/10.1145/3310000/3300233/a3-amershi.html?ip=169.237.6.227&amp;id=3300233&amp;acc=ACTIVE%20SERVICE&amp;key=CA367851C7E3CE77%2EBD0EBCE24FE9A3C5%2E4D4702B0C3E38B35%2E4D4702B0C3E38B35&amp;__acm__=1575108223_4c676709117010e6d07bffafb2c8e6c5#fig1">1</a> d shows an aggregate of all applicable ratings, including neutral responses. Finally, Table <a class="tbl" href="http://delivery.acm.org/10.1145/3310000/3300233/a3-amershi.html?ip=169.237.6.227&amp;id=3300233&amp;acc=ACTIVE%20SERVICE&amp;key=CA367851C7E3CE77%2EBD0EBCE24FE9A3C5%2E4D4702B0C3E38B35%2E4D4702B0C3E38B35&amp;__acm__=1575108223_4c676709117010e6d07bffafb2c8e6c5#tab1">1</a> shows example applications participants provided for each guideline (marked as “clearly applied” by the participant).</p> <p>In this analysis, we use the following interpretation constructs to better understand results from Figure&nbsp;<a class="fig" href="http://delivery.acm.org/10.1145/3310000/3300233/a3-amershi.html?ip=169.237.6.227&amp;id=3300233&amp;acc=ACTIVE%20SERVICE&amp;key=CA367851C7E3CE77%2EBD0EBCE24FE9A3C5%2E4D4702B0C3E38B35%2E4D4702B0C3E38B35&amp;__acm__=1575108223_4c676709117010e6d07bffafb2c8e6c5#fig1">1</a>. First, we use the total number of applications and violations as an indicator of the overall evidence of a guideline being relevant (e.g., Guidelines 1, 12, 17). Second, relevant guidelines with a high positive difference between the number of applications and violations are guidelines which are not only relevant but also widely implemented for the set of products in the study (e.g., Guidelines 1, 4, 12). Third, relevant guidelines with a high negative difference between the number of applications and violations are guidelines which, despite their importance, are still not widely implemented (e.g., Guidelines 2, 11, 17). Fourth, we discuss guidelines with the highest numbers of ”does not apply” (e.g., Guidelines 3, 5, 6).</p> <p>Participants found at least one application or violation of each of our guidelines in each product category we tested, suggesting broad evidence of the guidelines’ relevance. While participants were able to identify examples of each guideline in most of the product categories we tested, voice assistants had the largest number of “does not apply” instances reported, while photo organizers, activity trackers and voice assistants had the fewest numbers of total applications or violations. Interestingly, each of these product categories involves a mode of operation or input data type beyond simple graphical user interfaces and text (specifically, interaction over images or sensor data, or voice-based interaction).</p> <p>No instances of Guideline 10 “Scope services when in doubt” were reported for the two social networks we tested and no instances of Guideline 14 “Update and adapt cautiously” were reported for the two activity trackers. Some participants reported that these guidelines were hard to observe in a single session or without knowledge about the underlying AI algorithms. For example, one participant noted that Guideline 10 was “More difficult to assess unless you have a lengthy period of time with the product - and potential guidance for understanding the behind-the-scenes mechanisms,” possibly referring to understanding when the AI system was “in doubt”. Similarly, for Guideline 14, one participant said, “It's a bit difficult to assess this in a single session.” These guidelines were, however, observed in all other products that participants tested in our study, so such difficulty could be attributed to the guidelines not being applied or being difficult to observe in these particular products.</p> <p>Relevant guidelines that have significantly (at least 40%) more applications than violations are evidence of being widely implemented across products. This is also an indicator that there exist current mechanisms in the intersection of AI and design that facilitate the implementation of such guidelines. For example, frequent item sets and location detection were two common mechanisms used to support Guideline 4 in showing contextually relevant information (e.g., [E-commerce, Product #2] “The feature assumes I'm about to buy a gaming console and shows accessories and games that would go with it...” or [Web Search, Product #2] “Searching a movie title returns show times near my location for today's date”). For Guideline 12, multiple products leverage the history of user interactions to suggest a reduced cache of items that might be more useful to the user (e.g., [Navigation, Product #1] “Opening the app shows a list of recent destinations, as well as allows you to access ’favorite’ locations.”).</p> <p>Some guidelines emerged as relevant, but not widely implemented, as indicated by the large number of violations. For example, Guideline 11 “Make clear why the system did what it did” had one of the highest number of violations, despite the large volume of active research in the area of intelligibility and explanations. This guideline also had one of the fewest reported instances of “does not apply”, suggesting that participants could imagine opportunities for explanations, but were often unable to obtain them. In some cases, participants reported violations when they were unable to locate any explanation at all (e.g., [E-commerce, Product #1] “I have no idea why this is being shown to me. Is it trying to sell me stuff I do not need?” and [Music Recommender, Product #1] “Even when drilling down into a song there is no explanation for why this particular song was recommended.”). In other cases, participants reported violations when explanations were provided but were seemingly inadequate for their purposes (e.g., [Email, Product #1] “This does list out things which affect it, but they don't explain it in a clear manner. Do each of these affect it equally?” and [Navigation, Product #1] “It always says the suggested route is the “best route” but it doesn't give you the criteria for why that route is the best.”). These results suggest that participants could envision explanations being useful in most of the products we tested, but more work is necessary to understand the level of explanations people may desire and how designers can produce them. In some cases, explanations might be undesirable, for financial or business reasons (e.g. adversarial (gaming) behavior by Web page authors would be exacerbated if search engines explained their ranking.).</p> <p>Guidelines 3, 5, and 6 had the highest number of ”does not apply” ratings. Several participants indicated that Guideline 3 was not applicable because the products they were testing presented services only when explicitly requested by the user. For example, for one of the E-commerce products, one participant stated, “I feel this guideline does not apply for the recommendations page. It [is] a very ‘pull’ kind of interaction.”; i.e., the user views recommendations while browsing and there are no ‘push’ notifications. Similarly, for one of the Web Search engines we tested, one participant stated, “[the search engine] does not generally interrupt a user at any point. The mobile app has notifications, which might be relevant here, but the desktop website does not. Generally speaking, AI services pop up based on when the user searches and what he or she searches for, not based on an ongoing session.” This guideline is therefore likely more relevant for products that take proactive actions without explicit user requests, such as sending notifications.</p> <p>Guideline 5 “Match relevant social norms” and Guideline 6 “Mitigate social biases” had some of the most reported instances of “does not apply”. Examination of these instances revealed that in some cases participants firmly believed these guidelines were not relevant for the products they were testing while other participants reported either applications or violations of these guidelines in those same product categories. For example, one participant reported about one of the navigation products tested that “information is not subject to biases, unless users are biased against fastest route”. However, a different participant was able to identify a violation of this guideline for the same product category “Regards the ‘Walking’ transport there's no way to set an average walking speed. [The product] assumes users to be healthy.” Similarly, one participant reported about one of the voice assistants we tested that “Nothing in this interaction had any social biases that it could reinforce.”, while another stated about the same product that “While it's nice that a male voice is given as an option, the default [voice assistant] voice is female, which reinforces stereotypical gender roles that presume a secretary or receptionist is female.” Some participants, however, had no trouble identifying bias: ”I typed in ’black’ in the search bar and it came back with images of me as well as my niece [...] it saw a black face and used that as its frame of reference for all pictures, then returned all pictures of me and my family without images of other black spaces in an environment”.</p> <p>Guidelines 5 and 6 were noted as the least clear by our participants in their (see Figure <a class="fig" href="http://delivery.acm.org/10.1145/3310000/3300233/a3-amershi.html?ip=169.237.6.227&amp;id=3300233&amp;acc=ACTIVE%20SERVICE&amp;key=CA367851C7E3CE77%2EBD0EBCE24FE9A3C5%2E4D4702B0C3E38B35%2E4D4702B0C3E38B35&amp;__acm__=1575108223_4c676709117010e6d07bffafb2c8e6c5#fig2">2</a>), with several participants remarking about the difficulty of imagining social norms beyond their own or recognizing potential sources of bias (e.g., “Hard for a designer to implement, because it requires them to think outside of their own social context”, “Doesn't apply to me but to potential other people.”, and “This is hard to measure. Who defines what is undesirable and unfair?”). These assessments suggest that a diverse set of evaluators may be necessary to effectively recognize or apply these guidelines in practice. Alternatively, designers may need specific training or tools to recognize social norms and biases. GenderMag[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="http://delivery.acm.org/10.1145/3310000/3300233/a3-amershi.html?ip=169.237.6.227&amp;id=3300233&amp;acc=ACTIVE%20SERVICE&amp;key=CA367851C7E3CE77%2EBD0EBCE24FE9A3C5%2E4D4702B0C3E38B35%2E4D4702B0C3E38B35&amp;__acm__=1575108223_4c676709117010e6d07bffafb2c8e6c5#BibPLXBIB0005" data-original-title="" title="" id="auto-BibPLXBIB000564">5</a>], a method for identifying gender biases in user interfaces, is one such tool, but further work is needed in this area.</p> </section> <section id="sec-13"> <header> <div class="title-info"> <h4> <span class="section-number"><span class="nav-open" id="nav-open" onclick="openNav(this)" title="navigate to" tabindex="0"> </span></span> Clarity and Clarifications.</h4> </div> </header> <figure id="fig2"> <img src="./paper-chi-algorithm-3_files/chi2019-3-fig2.jpg" class="img-responsive" alt="" longdesc="Summary of subjective responses from user study participants about the clarity of each of the guidelines."> <div class="figure-caption"> <span class="figure-number">Figure 2:</span> <span class="figure-title">Subjective evaluations by study participants about the clarity of the 18 AI design guidelines.</span> </div> </figure> <p>Figure&nbsp;<a class="fig" href="http://delivery.acm.org/10.1145/3310000/3300233/a3-amershi.html?ip=169.237.6.227&amp;id=3300233&amp;acc=ACTIVE%20SERVICE&amp;key=CA367851C7E3CE77%2EBD0EBCE24FE9A3C5%2E4D4702B0C3E38B35%2E4D4702B0C3E38B35&amp;__acm__=1575108223_4c676709117010e6d07bffafb2c8e6c5#fig2">2</a> presents clarity ratings for all guidelines. To identify guidelines in need of further clarification, we reviewed these ratings and the 56 misinterpretations explained in the section Adjustments and Misinterpretations. We noted guidelines as needing further clarification when errors were determined to be systematic, which we defined as having four or more instances confused with another guideline or having multiple participants making similar comments about clarity. From this analysis, we identified and addressed the following issues:</p> <p>Guidelines 1, 2, and 11 (originally phrased as “Make capabilities clear”, “Set expectations of quality” and “Make explanations of behavior available”) had 13 misinterpreted instances (5 between Guidelines 1 and 2; 8 between Guidelines 1 and 11) and several comments about these being hard to differentiate (e.g., one participant commented on Guideline 2 that “I don't know what is different between this guideline and the guideline #1”). To clarify, we revised these guidelines using parallel language while emphasizing the intended differences (Guideline 1 is about <em>what</em> the system can do, Guideline 2 is about how <em>well</em> the system can do it, and Guideline 11 is about explaining <em>why</em> something happened, after the fact).</p> <p>Guideline 4 (originally phrased as “Show contextually relevant information. Display information about the user's inferred goals and attention during interaction.”) was confused with Guideline 13 (originally phrased as “Learn from user behavior. Personalize the experience based on the user's past actions”) six times. Examination revealed that most of these errors were due to “preferences” and “personalization” being considered as “relevant context”. To clarify, we rephrased these guidelines as in Table <a class="tbl" href="http://delivery.acm.org/10.1145/3310000/3300233/a3-amershi.html?ip=169.237.6.227&amp;id=3300233&amp;acc=ACTIVE%20SERVICE&amp;key=CA367851C7E3CE77%2EBD0EBCE24FE9A3C5%2E4D4702B0C3E38B35%2E4D4702B0C3E38B35&amp;__acm__=1575108223_4c676709117010e6d07bffafb2c8e6c5#tab1">1</a>, emphasizing the difference between a user's “current context” (e.g., “current task and environment”) and personalization which we intended to mean learning about preferences “over time”.</p> <p>Guidelines 3 and 4 (originally phrased as “Time services based on context” and “Show contextually relevant information”) were confused with each other in four instances. Several participants commented that this was because <em>what</em> is displayed and <em>when</em> it is displayed are often related (e.g., “provide the right information at the right time” and “The time when I'm specifically looking for DP to HDMI cable should be the most ideal time to recommend possible variations in DP to HDMI”). However, we decided to keep these guidelines separate to avoid conjunctions and updated Guideline 3 to use the same language of “current task and environment” as Guideline 4.</p> <p>Guideline 12 (originally phrased as “Maintain working memory”) was confused with Guideline 13 (“Learn from user behavior”) seven times, seemingly because the term “memory” was being interpreted as something that happens over time. To clarify, we revised these guidelines as in Table&nbsp;<a class="tbl" href="http://delivery.acm.org/10.1145/3310000/3300233/a3-amershi.html?ip=169.237.6.227&amp;id=3300233&amp;acc=ACTIVE%20SERVICE&amp;key=CA367851C7E3CE77%2EBD0EBCE24FE9A3C5%2E4D4702B0C3E38B35%2E4D4702B0C3E38B35&amp;__acm__=1575108223_4c676709117010e6d07bffafb2c8e6c5#tab1">1</a> to emphasize the difference between maintaining short term memory of recent interactions and learning behaviors over time.</p> <p>Guidelines 15 and 17 (originally phrased as “Encourage feedback” and “Provide global controls”, respectively) were confused six times, seemingly because the difference between local (or instance-level) feedback and global feedback (e.g., settings that impact behaviors on all instances) was still unclear despite introducing the term “global” after our first heuristic evaluation in Phase 2. We therefore revised these Guidelines as in Table <a class="tbl" href="http://delivery.acm.org/10.1145/3310000/3300233/a3-amershi.html?ip=169.237.6.227&amp;id=3300233&amp;acc=ACTIVE%20SERVICE&amp;key=CA367851C7E3CE77%2EBD0EBCE24FE9A3C5%2E4D4702B0C3E38B35%2E4D4702B0C3E38B35&amp;__acm__=1575108223_4c676709117010e6d07bffafb2c8e6c5#tab1">1</a> to further emphasize that Guideline 15 is about granular feedback that happens during a specific interaction, while Guideline 17 is about global customization of behaviors.</p> <p>These revisions resulted in the final set of guidelines presented in Table <a class="tbl" href="http://delivery.acm.org/10.1145/3310000/3300233/a3-amershi.html?ip=169.237.6.227&amp;id=3300233&amp;acc=ACTIVE%20SERVICE&amp;key=CA367851C7E3CE77%2EBD0EBCE24FE9A3C5%2E4D4702B0C3E38B35%2E4D4702B0C3E38B35&amp;__acm__=1575108223_4c676709117010e6d07bffafb2c8e6c5#tab1">1</a>, which we further evaluated with experts as described in the following section.</p> </section> </section> </section> <section id="sec-14"> <header> <div class="title-info"> <h2> <span class="section-number"><span class="nav-open" id="nav-open" onclick="openNav(this)" title="navigate to" tabindex="0">6</span></span> PHASE 4: EXPERT EVALUATION OF REVISIONS</h2> </div> </header> <p>To verify whether the revisions we proposed in the previous section improved our guidelines, we conducted an expert review. Expert reviews have been shown to be effective at identifying problems related to wording and clarity [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="http://delivery.acm.org/10.1145/3310000/3300233/a3-amershi.html?ip=169.237.6.227&amp;id=3300233&amp;acc=ACTIVE%20SERVICE&amp;key=CA367851C7E3CE77%2EBD0EBCE24FE9A3C5%2E4D4702B0C3E38B35%2E4D4702B0C3E38B35&amp;__acm__=1575108223_4c676709117010e6d07bffafb2c8e6c5#BibPLXBIB0027" data-original-title="" title="" id="auto-BibPLXBIB002765">27</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="http://delivery.acm.org/10.1145/3310000/3300233/a3-amershi.html?ip=169.237.6.227&amp;id=3300233&amp;acc=ACTIVE%20SERVICE&amp;key=CA367851C7E3CE77%2EBD0EBCE24FE9A3C5%2E4D4702B0C3E38B35%2E4D4702B0C3E38B35&amp;__acm__=1575108223_4c676709117010e6d07bffafb2c8e6c5#BibPLXBIB0034" data-original-title="" title="" id="auto-BibPLXBIB003466">34</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="http://delivery.acm.org/10.1145/3310000/3300233/a3-amershi.html?ip=169.237.6.227&amp;id=3300233&amp;acc=ACTIVE%20SERVICE&amp;key=CA367851C7E3CE77%2EBD0EBCE24FE9A3C5%2E4D4702B0C3E38B35%2E4D4702B0C3E38B35&amp;__acm__=1575108223_4c676709117010e6d07bffafb2c8e6c5#BibPLXBIB0043" data-original-title="" title="" id="auto-BibPLXBIB004367">43</a>]. For this purpose, we defined experts as people who have work experience in UX/HCI and who are familiar with discount usability methods such as heuristic evaluation. We reasoned that experts with experience in applying various guidelines to design solutions would be able to assess whether our guidelines would be easy to understand and therefore to work with.</p> <p>We recruited 11 experts (6 female, 5 male) from the same large company through snowball sampling. Of these experts, 6 were UX designers, 3 were UX researchers, and two were in research and product planning roles. Their length of experience working in UX or HCI was more than 20 years (1), 16-20 years (4), 11-15 years (3), and 2-5 years (3). Participants self-reported their familiarity with discount usability methods as very high (5), high (4), and medium (2).</p> <p>First, we asked each expert to review the 9 revised guidelines independently. They chose, for each guideline, the version they thought was easier to understand (the old version or the version we revised after in Phase 3). Then the experts reviewed the pairs of guidelines that emerged in Phase 3 as confusing or overlapping. For each pair, we asked experts to rate whether the two guidelines mean the same thing and the difficulty of distinguishing between them. We compensated participants with a <font style="normal">$</font>30 gift card for an estimated time commitment of 45 minutes. </p><figure id="fig3"> <img src="./paper-chi-algorithm-3_files/chi2019-3-fig3.jpg" class="img-responsive" alt="" longdesc="Summary of user study participant preferences for revised versions of the guidelines over earlier versions."> <div class="figure-caption"> <span class="figure-number">Figure 3:</span> <span class="figure-title">Number of experts out of 11 who preferred the revised or the old version. One participant suggested their own alternative for Guideline 3.</span> </div> </figure> <p></p> <p>Figure&nbsp;<a class="fig" href="http://delivery.acm.org/10.1145/3310000/3300233/a3-amershi.html?ip=169.237.6.227&amp;id=3300233&amp;acc=ACTIVE%20SERVICE&amp;key=CA367851C7E3CE77%2EBD0EBCE24FE9A3C5%2E4D4702B0C3E38B35%2E4D4702B0C3E38B35&amp;__acm__=1575108223_4c676709117010e6d07bffafb2c8e6c5#fig3">3</a> shows that experts preferred the revised versions for all but Guideline 15. Revisions appear to have helped distinguish between the pairs of guidelines Phase 3 participants had trouble with, but five experts still found Guidelines 1 and 2 somewhat difficult to distinguish (Table&nbsp;<a class="tbl" href="http://delivery.acm.org/10.1145/3310000/3300233/a3-amershi.html?ip=169.237.6.227&amp;id=3300233&amp;acc=ACTIVE%20SERVICE&amp;key=CA367851C7E3CE77%2EBD0EBCE24FE9A3C5%2E4D4702B0C3E38B35%2E4D4702B0C3E38B35&amp;__acm__=1575108223_4c676709117010e6d07bffafb2c8e6c5#tab4">4</a>). Since the revision of Guideline 15 made it easy to distinguish it from 17, we decided to keep it.</p> <p>Table <a class="tbl" href="http://delivery.acm.org/10.1145/3310000/3300233/a3-amershi.html?ip=169.237.6.227&amp;id=3300233&amp;acc=ACTIVE%20SERVICE&amp;key=CA367851C7E3CE77%2EBD0EBCE24FE9A3C5%2E4D4702B0C3E38B35%2E4D4702B0C3E38B35&amp;__acm__=1575108223_4c676709117010e6d07bffafb2c8e6c5#tab3">3</a> illustrates the evolution of the f<str two="" guidelines="" through="" the="" four="" phases.<="" p=""> </str></p><div class="table-responsive" id="tab3"> <div class="table-caption"> <span class="table-number">Table 3:</span> <span class="table-title">Evolution of Guidelines 1 and 2.</span> </div> <table class="table"> <tbody> <tr> <td><strong>Phase 1: Consolidating guidelines</strong></td> </tr> <tr> <td>Set appropriate expectations.</td> </tr> <tr> <td>Set accurate expectations to give people a clear idea of what the experience is and isn't capable of doing.</td> </tr> <tr> <td><strong>Phase 2: Internal evaluation</strong></td> </tr> <tr> <td>Set appropriate expectations.</td> </tr> <tr> <td><strong>Phase 3: User study</strong></td> </tr> <tr> <td>G1: Make capabilities clear. Help the user understand what the AI system is capable of doing.</td> </tr> <tr> <td>G2: Set expectations of quality. Help the user understand what level of performance the AI system is capable of delivering.</td> </tr> <tr> <td><strong>Phase 4: Expert evaluation of revisions</strong></td> </tr> <tr> <td>G1: Make clear what the system can do. Help the user understand what the AI system is capable of doing.</td> </tr> <tr> <td>G2: Make clear how well the system can do what it can do. Help the user understand how often the AI system may make mistakes.</td> </tr> </tbody> </table> </div> </section> <section id="sec-15"> <header> <div class="title-info"> <h2> <span class="section-number"><span class="nav-open" id="nav-open" onclick="openNav(this)" title="navigate to" tabindex="0">7</span></span> Discussion &amp; Future Work</h2> </div> </header> <p>We synthesized guidance proposed over the past 20 years about the design of human-AI interaction into a set of 18 AI usability guidelines. These guidelines were iteratively refined in four phases by a team of 11 researchers, and were applied or reviewed by an additional 60 designers and usability practitioners. Over the various stages of development, the guidelines were applied to AI-infused products across 10 product categories. These efforts provide evidence for the relevance of the guidelines across a wide range of common AI-infused systems. In terms of utility, we anticipate the guidelines will be useful to evaluate existing products and emerging design ideas. Our evaluation methods show that the guidelines lend themselves well to usability inspection methods such as heuristic evaluation. Future work could examine the uses and value of these guidelines at various stages of design.</p> <p>We recognize that there is a tradeoff between generality and specialization, and that these guidelines might not adequately address all types of AI-infused systems. For example, we reported that some guidelines do not directly apply to AI systems that lack graphical user interfaces (e.g., voice-based virtual assistants and activity trackers). Additional guidelines may be necessary to help designers and developers create intuitive and effective products with these properties or in these product categories. Likewise, specialized guidelines may be required in certain high-risk or highly regulated areas such as semi-autonomous vehicles, robot-assisted surgery, and financial systems. We hope the 18 guidelines presented here and their validation process stimulate and inform future research into the development of domain-specific guidance.</p> <p>Our work also intentionally focused on AI design guidelines that we believed could be easily evaluated by inspection of a system's interface. For example, we excluded broad principles such as ”build trust”, and focused instead on specific and observable guidelines that are likely to contribute to building trust. Previous work, however, has proposed guidelines that impact the usability of AI-infused systems but must be considered when constructing the AI model. For example, we excluded Horvitz's [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="http://delivery.acm.org/10.1145/3310000/3300233/a3-amershi.html?ip=169.237.6.227&amp;id=3300233&amp;acc=ACTIVE%20SERVICE&amp;key=CA367851C7E3CE77%2EBD0EBCE24FE9A3C5%2E4D4702B0C3E38B35%2E4D4702B0C3E38B35&amp;__acm__=1575108223_4c676709117010e6d07bffafb2c8e6c5#BibPLXBIB0017" data-original-title="" title="" id="auto-BibPLXBIB001768">17</a>] principle of “inferring ideal action in light of costs, benefits, and uncertainties” and guidance about being “especially conservative in the beginning” because these require decisions to be made at the modeling layer of a system. We foresee the value of future work to investigate how designers and model developers can work together to effectively apply these guidelines in AI-infused systems. For example, given the expected performance of an AI model, designers may recommend specific designs that reduce costs while optimizing benefits to users (e.g., displaying multiple options to users until the performance of the AI model is improved enough to take proactive action on the user's behalf).</p> <p>Our decisions to optimize for generality, and to focus on observable properties, serve as a reminder that interaction designers routinely encounter these types of trade-offs. We anticipate situations where there will be interactions and trade-offs in attempts to employ several of the guidelines. As an example, if a system uses a complex or deep model to achieve a high level of performance, it may be challenging to both convey the consequences of user actions (Guideline 16), while also actively learning from user behavior (Guideline 13). Further research is necessary to understand the implications of these potential interactions and trade-offs for the design of AI systems and to understand how designers employ these guidelines ”in the wild.”</p> <p>Finally, we recognize that our guidelines only begin to touch on topics of fairness and broader ethical considerations. Ethical concerns extend beyond the matching of social norms (Guideline 5) and mitigating social biases (Guideline 6). As an example, an AI system may adhere to each of these guidelines and yet impact people's lives or livelihoods in a consequential manner. It is imperative that system designers carefully evaluate the many influences of AI technologies on people and society, and that this remains a topic of ongoing research and intense interest. Ethics-focused guidelines can be difficult to fully evaluate in a heuristic evaluation, and successful detection of problems may depend on who is performing the evaluation. Our results related to Guidelines 5 “Match relevant social norms” and 6 “Mitigate social biases” suggest that diversity among evaluators helps identify a range of issues that might be invisible to members of majority groups.</p> <div class="table-responsive" id="tab4"> <div class="table-caption"> <span class="table-number">Table 4:</span> <span class="table-title">Number of experts out of 11 who rated each pair of guidelines as different in meaning and distinguishable.</span> </div> <table class="table"> <tbody> <tr> <td> <img src="./paper-chi-algorithm-3_files/chi19-3-img2.svg" class="img-responsive" alt=""> </td> </tr> </tbody> </table> </div> </section> <section id="sec-16"> <header> <div class="title-info"> <h2> <span class="section-number"><span class="nav-open" id="nav-open" onclick="openNav(this)" title="navigate to" tabindex="0">8</span></span> CONCLUSION</h2> </div> </header> <p>We proposed and evaluated 18 generally applicable design guidelines for human-AI interaction. We distilled the guidelines from over 150 AI-related design recommendations and validated them through three rounds of evaluation. We are hopeful that application of these guidelines will result in better, more human-centric AI-infused systems, and that our synthesis can facilitate further research. As the current technology landscape is shifting towards the increasing inclusion of AI in computing applications, we see significant value in working to further develop and refine design guidelines for human-AI interaction.</p> </section> <section id="sec-17"> <header> <div class="title-info"> <h2> <span class="section-number"><span class="nav-open" id="nav-open" onclick="openNav(this)" title="navigate to" tabindex="0">9</span></span> ACKNOWLEDGMENTS</h2> </div> </header> <p>The authors would like to acknowledge the contributions of our newest team member, Ever Zayn McDonald.</p> </section> </section> <section class="back-matter"> <section id="ref-001"> <header> <div class="title-info"> <h2 class="page-brake-head"><span class="nav-open" id="nav-open" onclick="openNav(this)" tabindex="0" title="navigate to">REFERENCES</span></h2> </div> </header> <ul class="bibUl"> <li id="BibPLXBIB0001" label="[1]" value="1">Alexa. 2018. Top sites in the United States. Retrieved July, 2018 from <a class="link-inline force-break" href="https://www.alexa.com/topsites/countries/US">https://www.alexa.com/topsites/countries/US</a> <span class="link-das"> </span><select class="bib-ref-num" aria-label="Jump to citation for reference 1" style="display:inline-block;"><option>Navigate to</option><option value="#auto-BibPLXBIB000159" aria-label="citation 1 reference 1">citation 1</option></select></li> <li id="BibPLXBIB0002" label="[2]" value="2">Kathy Baxter. 2017. How to Meet User Expectations for Artificial Intelligence. Medium. Retrieved September, 2018 from <a class="link-inline force-break" href="https://medium.com/salesforce-ux/how-to-meet-user-expectations-for-artificial-intelligence-a51d3c82af6">https://medium.com/salesforce-ux/how-to-meet-user-expectations-for-artificial-intelligence-a51d3c82af6</a> <span class="link-das"> </span><select class="bib-ref-num" aria-label="Jump to citation for reference 2" style="display:inline-block;"><option>Navigate to</option><option value="#auto-BibPLXBIB000243" aria-label="citation 1 reference 2">citation 1</option><option value="#auto-BibPLXBIB000253" aria-label="citation 2 reference 2">citation 2</option></select></li> <li id="BibPLXBIB0003" label="[3]" value="3">Victoria Bellotti and Keith Edwards. 2001. Intelligibility and Accountability: Human Considerations in Context-Aware Systems. <em><em>Human–Computer Interaction</em></em> 16, 2-4 (2001), 193–212. <span class="link-das"> </span><select class="bib-ref-num" aria-label="Jump to citation for reference 3" style="display:inline-block;"><option>Navigate to</option><option value="#auto-BibPLXBIB000338" aria-label="citation 1 reference 3">citation 1</option></select></li> <li id="BibPLXBIB0004" label="[4]" value="4">Andrea Bunt, Matthew Lount, and Catherine Lauzon. 2012. Are Explanations Always Important?: A Study of Deployed, Low-cost Intelligent Interactive Systems. In <em>Proc. IUI ’12</em>. ACM, New York, NY, USA, 169–178. <span class="link-das"> </span><select class="bib-ref-num" aria-label="Jump to citation for reference 4" style="display:inline-block;"><option>Navigate to</option><option value="#auto-BibPLXBIB000450" aria-label="citation 1 reference 4">citation 1</option></select></li> <li id="BibPLXBIB0005" label="[5]" value="5">Margaret Burnett, Simone Stumpf, Jamie Macbeth, Stephann Makri, Laura Beckwith, Irwin Kwan, Anicia Peters, and William Jernigan. 2016. GenderMag: A method for evaluating software's gender inclusiveness. <em><em>Interacting with Computers</em></em> 28, 6 (2016), 760–787. <span class="link-das"> </span><select class="bib-ref-num" aria-label="Jump to citation for reference 5" style="display:inline-block;"><option>Navigate to</option><option value="#auto-BibPLXBIB000564" aria-label="citation 1 reference 5">citation 1</option></select></li> <li id="BibPLXBIB0006" label="[6]" value="6">comScore. 2018. Latest rankings. Retrieved July, 2018 from <a class="link-inline force-break" href="https://www.comscore.com/Insights/Rankings">https://www.comscore.com/Insights/Rankings</a> <span class="link-das"> </span><select class="bib-ref-num" aria-label="Jump to citation for reference 6" style="display:inline-block;"><option>Navigate to</option><option value="#auto-BibPLXBIB000660" aria-label="citation 1 reference 6">citation 1</option></select></li> <li id="BibPLXBIB0007" label="[7]" value="7">Maartje de Graaf, Somaya Ben&nbsp;Allouch, and Jan van Dijk. 2017. Why Do They Refuse to Use My Robot?: Reasons for Non-Use Derived from a Long-Term Home Study. In <em>Proc. HRI ’17</em>. ACM, New York, NY, USA, 224–233. <span class="link-das"> </span><select class="bib-ref-num" aria-label="Jump to citation for reference 7" style="display:inline-block;"><option>Navigate to</option><option value="#auto-BibPLXBIB00073" aria-label="citation 1 reference 7">citation 1</option></select></li> <li id="BibPLXBIB0008" label="[8]" value="8">Defy Media. 2015. Damn You Auto Correct!Retrieved September, 2018 from <a class="link-inline force-break" href="http://www.damnyouautocorrect.com/">http://www.damnyouautocorrect.com/</a> <span class="link-das"> </span><select class="bib-ref-num" aria-label="Jump to citation for reference 8" style="display:inline-block;"><option>Navigate to</option><option value="#auto-BibPLXBIB000815" aria-label="citation 1 reference 8">citation 1</option></select></li> <li id="BibPLXBIB0009" label="[9]" value="9">T. Deuschel and T. Scully. 2016. On the Importance of Spatial Perception for the Design of Adaptive User Interfaces. In <em>2016 IEEE 10th International Conference on Self-Adaptive and Self-Organizing Systems (SASO)</em>. 70–79. <span class="link-das"> </span><select class="bib-ref-num" aria-label="Jump to citation for reference 9" style="display:inline-block;"><option>Navigate to</option><option value="#auto-BibPLXBIB000929" aria-label="citation 1 reference 9">citation 1</option></select></li> <li id="BibPLXBIB0010" label="[10]" value="10">Anind Dey, Jennifer Mankoff, Gregory Abowd, and Scott Carter. 2002. Distributed Mediation of Ambiguous Context in Aware Environments. In <em>Proc. UIST ’02</em>. ACM, New York, NY, USA, 121–130. <span class="link-das"> </span><select class="bib-ref-num" aria-label="Jump to citation for reference 10" style="display:inline-block;"><option>Navigate to</option><option value="#auto-BibPLXBIB001040" aria-label="citation 1 reference 10">citation 1</option></select></li> <li id="BibPLXBIB0011" label="[11]" value="11">Leah Findlater and Joanna McGrenere. 2004. A Comparison of Static, Adaptive, and Adaptable Menus. In <em>Proc. CHI ’04</em>. ACM, New York, NY, USA, 89–96. <span class="link-das"> </span><select class="bib-ref-num" aria-label="Jump to citation for reference 11" style="display:inline-block;"><option>Navigate to</option><option value="#auto-BibPLXBIB001130" aria-label="citation 1 reference 11">citation 1</option></select></li> <li id="BibPLXBIB0012" label="[12]" value="12">Krzysztof&nbsp;Z. Gajos, Mary Czerwinski, Desney&nbsp;S. Tan, and Daniel&nbsp;S. Weld. 2006. Exploring the Design Space for Adaptive Graphical User Interfaces. In <em>Proc. AVI ’06</em>. ACM, New York, NY, USA, 201–208. <span class="link-das"> </span><select class="bib-ref-num" aria-label="Jump to citation for reference 12" style="display:inline-block;"><option>Navigate to</option><option value="#auto-BibPLXBIB001231" aria-label="citation 1 reference 12">citation 1</option></select></li> <li id="BibPLXBIB0013" label="[13]" value="13">Krzysztof&nbsp;Z Gajos, Katherine Everitt, Desney&nbsp;S Tan, Mary Czerwinski, and Daniel&nbsp;S Weld. 2008. Predictability and accuracy in adaptive user interfaces. In <em>CHI</em>. ACM, 1271–1274. <span class="link-das"> </span><select class="bib-ref-num" aria-label="Jump to citation for reference 13" style="display:inline-block;"><option>Navigate to</option><option value="#auto-BibPLXBIB001332" aria-label="citation 1 reference 13">citation 1</option></select></li> <li id="BibPLXBIB0014" label="[14]" value="14">Jonathan&nbsp;L. Herlocker, Joseph&nbsp;A. Konstan, and John Riedl. 2000. Explaining Collaborative Filtering Recommendations. In <em>Proc. CSCW ’00</em>. ACM, New York, NY, USA, 241–250. <span class="link-das"> </span><select class="bib-ref-num" aria-label="Jump to citation for reference 14" style="display:inline-block;"><option>Navigate to</option><option value="#auto-BibPLXBIB00145" aria-label="citation 1 reference 14">citation 1</option><option value="#auto-BibPLXBIB001423" aria-label="citation 2 reference 14">citation 2</option></select></li> <li id="BibPLXBIB0015" label="[15]" value="15">Setia Hermawati and Glyn Lawson. 2016. Establishing usability heuristics for heuristics evaluation in a specific domain: Is there a consensus?<em><em>Applied Ergonomics</em></em> 56(2016), 34 – 51. <span class="link-das"> </span><select class="bib-ref-num" aria-label="Jump to citation for reference 15" style="display:inline-block;"><option>Navigate to</option><option value="#auto-BibPLXBIB001552" aria-label="citation 1 reference 15">citation 1</option></select></li> <li id="BibPLXBIB0016" label="[16]" value="16">Kristina Höök. 2000. Steps to take before intelligent user interfaces become real. <em><em>Interacting with Computers</em></em> 12, 4 (2000), 409–426. <span class="link-das"> </span><select class="bib-ref-num" aria-label="Jump to citation for reference 16" style="display:inline-block;"><option>Navigate to</option><option value="#auto-BibPLXBIB001611" aria-label="citation 1 reference 16">citation 1</option><option value="#auto-BibPLXBIB001618" aria-label="citation 2 reference 16">citation 2</option><option value="#auto-BibPLXBIB001619" aria-label="citation 3 reference 16">citation 3</option></select></li> <li id="BibPLXBIB0017" label="[17]" value="17">Eric Horvitz. 1999. Principles of Mixed-Initiative User Interfaces. In <em>Proc. CHI ’99</em>. ACM, New York, NY, USA, 159–166. <span class="link-das"> </span><select class="bib-ref-num" aria-label="Jump to citation for reference 17" style="display:inline-block;"><option>Navigate to</option><option value="#auto-BibPLXBIB001712" aria-label="citation 1 reference 17">citation 1</option><option value="#auto-BibPLXBIB001722" aria-label="citation 2 reference 17">citation 2</option><option value="#auto-BibPLXBIB001751" aria-label="citation 3 reference 17">citation 3</option><option value="#auto-BibPLXBIB001768" aria-label="citation 4 reference 17">citation 4</option></select></li> <li id="BibPLXBIB0018" label="[18]" value="18">Eric Horvitz, Jack Breese, David Heckerman, David Hovel, and Koos Rommelse. 1998. The Lumière Project: Bayesian User Modeling for Inferring the Goals and Needs of Software Users. In <em>Proc. UAI ’98</em>. Morgan Kaufmann Publishers Inc., San Francisco, CA, USA, 256–265. <span class="link-das"> </span><select class="bib-ref-num" aria-label="Jump to citation for reference 18" style="display:inline-block;"><option>Navigate to</option><option value="#auto-BibPLXBIB001833" aria-label="citation 1 reference 18">citation 1</option></select></li> <li id="BibPLXBIB0019" label="[19]" value="19">IDC Corporate USA. 2018. IDC: The premier global market intelligence firm. Retrieved September, 2018 from <a class="link-inline force-break" href="https://www.idc.com/">https://www.idc.com/</a> <span class="link-das"> </span><select class="bib-ref-num" aria-label="Jump to citation for reference 19" style="display:inline-block;"><option>Navigate to</option><option value="#auto-BibPLXBIB001962" aria-label="citation 1 reference 19">citation 1</option></select></li> <li id="BibPLXBIB0020" label="[20]" value="20">Anthony Jameson. 2008. Adaptive interfaces and agents. In The human-computer interaction handbook: Fundamentals, evolving technologies and emerging applications(2nd ed.), Andrew Sears and Julie&nbsp;A. Jacko (Eds.). CRC Press, Boca Raton, FL, 433–458. <span class="link-das"> </span><select class="bib-ref-num" aria-label="Jump to citation for reference 20" style="display:inline-block;"><option>Navigate to</option><option value="#auto-BibPLXBIB002020" aria-label="citation 1 reference 20">citation 1</option></select></li> <li id="BibPLXBIB0021" label="[21]" value="21">Todd Kulesza, Margaret Burnett, Weng-Keen Wong, and Simone Stumpf. 2015. Principles of Explanatory Debugging to Personalize Interactive Machine Learning. In <em>Proc. IUI ’15</em>. ACM, New York, NY, USA, 126–137. <span class="link-das"> </span><select class="bib-ref-num" aria-label="Jump to citation for reference 21" style="display:inline-block;"><option>Navigate to</option><option value="#auto-BibPLXBIB00216" aria-label="citation 1 reference 21">citation 1</option><option value="#auto-BibPLXBIB002124" aria-label="citation 2 reference 21">citation 2</option></select></li> <li id="BibPLXBIB0022" label="[22]" value="22">Chia-Jung Lee, Jaime Teevan, and Sebastian de&nbsp;la Chica. 2014. Characterizing Multi-click Search Behavior and the Risks and Opportunities of Changing Results During Use. In <em>Proc. SIGIR ’14</em>. ACM, New York, NY, USA, 515–524. <span class="link-das"> </span><select class="bib-ref-num" aria-label="Jump to citation for reference 22" style="display:inline-block;"><option>Navigate to</option><option value="#auto-BibPLXBIB00224" aria-label="citation 1 reference 22">citation 1</option><option value="#auto-BibPLXBIB002249" aria-label="citation 2 reference 22">citation 2</option></select></li> <li id="BibPLXBIB0023" label="[23]" value="23">Brian&nbsp;Y. Lim and Anind&nbsp;K. Dey. 2009. Assessing Demand for Intelligibility in Context-aware Applications. In <em>Proc. UbiComp ’09</em>. ACM, New York, NY, USA, 195–204. <span class="link-das"> </span><select class="bib-ref-num" aria-label="Jump to citation for reference 23" style="display:inline-block;"><option>Navigate to</option><option value="#auto-BibPLXBIB00237" aria-label="citation 1 reference 23">citation 1</option><option value="#auto-BibPLXBIB002325" aria-label="citation 2 reference 23">citation 2</option><option value="#auto-BibPLXBIB002339" aria-label="citation 3 reference 23">citation 3</option></select></li> <li id="BibPLXBIB0024" label="[24]" value="24">Josh Lovejoy. 2018. The UX of AI. Google Design. Retrieved September, 2018 from <a class="link-inline force-break" href="https://design.google/library/ux-ai/">https://design.google/library/ux-ai/</a> <span class="link-das"> </span><select class="bib-ref-num" aria-label="Jump to citation for reference 24" style="display:inline-block;"><option>Navigate to</option><option value="#auto-BibPLXBIB002444" aria-label="citation 1 reference 24">citation 1</option><option value="#auto-BibPLXBIB002454" aria-label="citation 2 reference 24">citation 2</option></select></li> <li id="BibPLXBIB0025" label="[25]" value="25">Josh Lovejoy and Jess Holbrook. 2017. Human-Centered Machine Learning. 7 steps to stay focused on the user when designing with ML. Medium. Retrieved September, 2018 from <a class="link-inline force-break" href="https://medium.com/google-design/human-centered-machine-learning-a770d10562cd">https://medium.com/google-design/human-centered-machine-learning-a770d10562cd</a> <span class="link-das"> </span><select class="bib-ref-num" aria-label="Jump to citation for reference 25" style="display:inline-block;"><option>Navigate to</option><option value="#auto-BibPLXBIB002545" aria-label="citation 1 reference 25">citation 1</option><option value="#auto-BibPLXBIB002555" aria-label="citation 2 reference 25">citation 2</option></select></li> <li id="BibPLXBIB0026" label="[26]" value="26">Ewa Luger and Abigail Sellen. 2016. ”Like Having a Really Bad PA”: The Gulf Between User Expectation and Experience of Conversational Agents. In <em>Proc. CHI ’16</em>. ACM, New York, NY, USA, 5286–5297. <span class="link-das"> </span><select class="bib-ref-num" aria-label="Jump to citation for reference 26" style="display:inline-block;"><option>Navigate to</option><option value="#auto-BibPLXBIB002614" aria-label="citation 1 reference 26">citation 1</option><option value="#auto-BibPLXBIB002635" aria-label="citation 2 reference 26">citation 2</option><option value="#auto-BibPLXBIB002648" aria-label="citation 3 reference 26">citation 3</option></select></li> <li id="BibPLXBIB0027" label="[27]" value="27">Aaron Maitland and Stanley Presser. 2016. How Accurately Do Different Evaluation Methods Predict the Reliability of Survey Questions?<em><em>Journal of Survey Statistics and Methodology</em></em> 4, 3(2016), 362–381. <span class="link-das"> </span><select class="bib-ref-num" aria-label="Jump to citation for reference 27" style="display:inline-block;"><option>Navigate to</option><option value="#auto-BibPLXBIB002765" aria-label="citation 1 reference 27">citation 1</option></select></li> <li id="BibPLXBIB0028" label="[28]" value="28">Joseph&nbsp;A Maxwell. 2012. <em>Qualitative research design: An interactive approach</em>. Vol.&nbsp;41. Sage publications. <span class="link-das"> </span><select class="bib-ref-num" aria-label="Jump to citation for reference 28" style="display:inline-block;"><option>Navigate to</option><option value="#auto-BibPLXBIB002858" aria-label="citation 1 reference 28">citation 1</option></select></li> <li id="BibPLXBIB0029" label="[29]" value="29">Chelsea Myers, Anushay Furqan, Jessica Nebolsky, Karina Caro, and Jichen Zhu. 2018. Patterns for How Users Overcome Obstacles in Voice User Interfaces. In <em>Proc. CHI ’18</em>. ACM, New York, NY, USA, Article 6, 7&nbsp;pages. <span class="link-das"> </span><select class="bib-ref-num" aria-label="Jump to citation for reference 29" style="display:inline-block;"><option>Navigate to</option><option value="#auto-BibPLXBIB002936" aria-label="citation 1 reference 29">citation 1</option></select></li> <li id="BibPLXBIB0030" label="[30]" value="30">Jakob Nielsen. 1992. Finding Usability Problems Through Heuristic Evaluation. In <em>Proc. CHI ’92</em>. ACM, New York, NY, USA, 373–380. <span class="link-das"> </span><select class="bib-ref-num" aria-label="Jump to citation for reference 30" style="display:inline-block;"><option>Navigate to</option><option value="#auto-BibPLXBIB003063" aria-label="citation 1 reference 30">citation 1</option></select></li> <li id="BibPLXBIB0031" label="[31]" value="31">Jakob Nielsen and Rolf Molich. 1990. Heuristic Evaluation of User Interfaces. In <em>Proc. CHI ’90</em>. ACM, New York, NY, USA, 249–256. <span class="link-das"> </span><select class="bib-ref-num" aria-label="Jump to citation for reference 31" style="display:inline-block;"><option>Navigate to</option><option value="#auto-BibPLXBIB00311" aria-label="citation 1 reference 31">citation 1</option><option value="#auto-BibPLXBIB003157" aria-label="citation 2 reference 31">citation 2</option></select></li> <li id="BibPLXBIB0032" label="[32]" value="32">D.A. Norman. 1988. <em>The psychology of everyday things</em>. Basic Books, New York. <span class="link-das"> </span><select class="bib-ref-num" aria-label="Jump to citation for reference 32" style="display:inline-block;"><option>Navigate to</option><option value="#auto-BibPLXBIB00322" aria-label="citation 1 reference 32">citation 1</option></select></li> <li id="BibPLXBIB0033" label="[33]" value="33">Donald&nbsp;A. Norman. 1994. How Might People Interact with Agents. <em><em>Commun. ACM</em></em> 37, 7 (July 1994), 68–71. <span class="link-das"> </span><select class="bib-ref-num" aria-label="Jump to citation for reference 33" style="display:inline-block;"><option>Navigate to</option><option value="#auto-BibPLXBIB003313" aria-label="citation 1 reference 33">citation 1</option><option value="#auto-BibPLXBIB003317" aria-label="citation 2 reference 33">citation 2</option><option value="#auto-BibPLXBIB003321" aria-label="citation 3 reference 33">citation 3</option><option value="#auto-BibPLXBIB003334" aria-label="citation 4 reference 33">citation 4</option></select></li> <li id="BibPLXBIB0034" label="[34]" value="34">Kristen Olson. 2010. An examination of questionnaire evaluation by expert reviewers. <em><em>Field Methods</em></em> 22, 4 (2010), 295–318. <span class="link-das"> </span><select class="bib-ref-num" aria-label="Jump to citation for reference 34" style="display:inline-block;"><option>Navigate to</option><option value="#auto-BibPLXBIB003466" aria-label="citation 1 reference 34">citation 1</option></select></li> <li id="BibPLXBIB0035" label="[35]" value="35">Martin Porcheron, Joel&nbsp;E. Fischer, Stuart Reeves, and Sarah Sharples. 2018. Voice Interfaces in Everyday Life. In <em>Proc. CHI ’18</em>. ACM, New York, NY, USA, Article 640, 12&nbsp;pages. <span class="link-das"> </span><select class="bib-ref-num" aria-label="Jump to citation for reference 35" style="display:inline-block;"><option>Navigate to</option><option value="#auto-BibPLXBIB003537" aria-label="citation 1 reference 35">citation 1</option></select></li> <li id="BibPLXBIB0036" label="[36]" value="36">Emilee Rader, Kelley Cotter, and Janghee Cho. 2018. Explanations As Mechanisms for Supporting Algorithmic Transparency. In <em>Proc. CHI ’18</em>. ACM, New York, NY, USA, Article 103, 13&nbsp;pages. <span class="link-das"> </span><select class="bib-ref-num" aria-label="Jump to citation for reference 36" style="display:inline-block;"><option>Navigate to</option><option value="#auto-BibPLXBIB00368" aria-label="citation 1 reference 36">citation 1</option><option value="#auto-BibPLXBIB003626" aria-label="citation 2 reference 36">citation 2</option></select></li> <li id="BibPLXBIB0037" label="[37]" value="37">Ruth Ravichandran, Sang-Wha Sien, Shwetak&nbsp;N. Patel, Julie&nbsp;A. Kientz, and Laura&nbsp;R. Pina. 2017. Making Sense of Sleep Sensors: How Sleep Sensing Technologies Support and Undermine Sleep Health. In <em>Proc. CHI ’17</em>. ACM, New York, NY, USA, 6864–6875. <span class="link-das"> </span><select class="bib-ref-num" aria-label="Jump to citation for reference 37" style="display:inline-block;"><option>Navigate to</option><option value="#auto-BibPLXBIB003741" aria-label="citation 1 reference 37">citation 1</option></select></li> <li id="BibPLXBIB0038" label="[38]" value="38">Marco&nbsp;Tulio Ribeiro, Sameer Singh, and Carlos Guestrin. 2016. ”Why Should I Trust You?”: Explaining the Predictions of Any Classifier. In <em>Proc. KDD ’16</em>. ACM, New York, NY, USA, 1135–1144. <span class="link-das"> </span><select class="bib-ref-num" aria-label="Jump to citation for reference 38" style="display:inline-block;"><option>Navigate to</option><option value="#auto-BibPLXBIB00389" aria-label="citation 1 reference 38">citation 1</option><option value="#auto-BibPLXBIB003827" aria-label="citation 2 reference 38">citation 2</option></select></li> <li id="BibPLXBIB0039" label="[39]" value="39">Katharine Schwab. 2017. 10 Principles For Design In The Age Of AI. Retrieved September, 2018 from <a class="link-inline force-break" href="https://www.fastcompany.com/3067632/10-principles-for-design-in-the-age-of-ai">https://www.fastcompany.com/3067632/10-principles-for-design-in-the-age-of-ai</a> <span class="link-das"> </span><select class="bib-ref-num" aria-label="Jump to citation for reference 39" style="display:inline-block;"><option>Navigate to</option><option value="#auto-BibPLXBIB003946" aria-label="citation 1 reference 39">citation 1</option><option value="#auto-BibPLXBIB003956" aria-label="citation 2 reference 39">citation 2</option></select></li> <li id="BibPLXBIB0040" label="[40]" value="40">SimilarWeb. 2018. Top websites ranking. Retrieved July, 2018 from <a class="link-inline force-break" href="https://www.similarweb.com/top-websites/united-states">https://www.similarweb.com/top-websites/united-states</a> <span class="link-das"> </span><select class="bib-ref-num" aria-label="Jump to citation for reference 40" style="display:inline-block;"><option>Navigate to</option><option value="#auto-BibPLXBIB004061" aria-label="citation 1 reference 40">citation 1</option></select></li> <li id="BibPLXBIB0041" label="[41]" value="41">Jack Stewart. 2018. Why Tesla's Autopilot Can't See a Stopped Firetruck. Retrieved September, 2018 from <a class="link-inline force-break" href="https://www.wired.com/story/tesla-autopilot-why-crash-radar/">https://www.wired.com/story/tesla-autopilot-why-crash-radar/</a> <span class="link-das"> </span><select class="bib-ref-num" aria-label="Jump to citation for reference 41" style="display:inline-block;"><option>Navigate to</option><option value="#auto-BibPLXBIB004116" aria-label="citation 1 reference 41">citation 1</option></select></li> <li id="BibPLXBIB0042" label="[42]" value="42">Erica Virtue. 2017. Designing with AI. <span class="link-das"> </span><select class="bib-ref-num" aria-label="Jump to citation for reference 42" style="display:inline-block;"><option>Navigate to</option><option value="#auto-BibPLXBIB004247" aria-label="citation 1 reference 42">citation 1</option></select></li> <li id="BibPLXBIB0043" label="[43]" value="43">Jolita Vveinhardt and Evelina Gulbovaitė. 2016. Expert evaluation of diagnostic instrument for personal and organizational value congruence. <em><em>Journal of business ethics</em></em> 136, 3 (2016), 481–501. <span class="link-das"> </span><select class="bib-ref-num" aria-label="Jump to citation for reference 43" style="display:inline-block;"><option>Navigate to</option><option value="#auto-BibPLXBIB004367" aria-label="citation 1 reference 43">citation 1</option></select></li> <li id="BibPLXBIB0044" label="[44]" value="44">Daniel&nbsp;S Weld and Gagan Bansal. 2018. Intelligible Artificial Intelligence. <em><em>arXiv preprint arXiv:1803.04263</em></em>(2018). <span class="link-das"> </span><select class="bib-ref-num" aria-label="Jump to citation for reference 44" style="display:inline-block;"><option>Navigate to</option><option value="#auto-BibPLXBIB004410" aria-label="citation 1 reference 44">citation 1</option><option value="#auto-BibPLXBIB004428" aria-label="citation 2 reference 44">citation 2</option></select></li> <li id="BibPLXBIB0045" label="[45]" value="45">Rayoung Yang, Eunice Shin, Mark&nbsp;W. Newman, and Mark&nbsp;S. Ackerman. 2015. When Fitness Trackers Don'T ’Fit’: End-user Difficulties in the Assessment of Personal Tracking Device Accuracy. In <em>Proc. UbiComp ’15</em>. ACM, New York, NY, USA, 623–634. <span class="link-das"> </span><select class="bib-ref-num" aria-label="Jump to citation for reference 45" style="display:inline-block;"><option>Navigate to</option><option value="#auto-BibPLXBIB004542" aria-label="citation 1 reference 45">citation 1</option></select></li> </ul> </section> </section> <section id="foot-001" class="footnote"> <header> <div class="title-info"> <h2><span class="nav-open" id="nav-open" onclick="openNav(this)" tabindex="0" title="navigate to">FOOTNOTE</span></h2> </div> </header> <p id="fn1"> <a href="http://delivery.acm.org/10.1145/3310000/3300233/a3-amershi.html?ip=169.237.6.227&amp;id=3300233&amp;acc=ACTIVE%20SERVICE&amp;key=CA367851C7E3CE77%2EBD0EBCE24FE9A3C5%2E4D4702B0C3E38B35%2E4D4702B0C3E38B35&amp;__acm__=1575108223_4c676709117010e6d07bffafb2c8e6c5#foot-fn1"><sup>⁎</sup></a>Work done as a visiting researcher at Microsoft Research.</p> <p id="fn2"> <a href="http://delivery.acm.org/10.1145/3310000/3300233/a3-amershi.html?ip=169.237.6.227&amp;id=3300233&amp;acc=ACTIVE%20SERVICE&amp;key=CA367851C7E3CE77%2EBD0EBCE24FE9A3C5%2E4D4702B0C3E38B35%2E4D4702B0C3E38B35&amp;__acm__=1575108223_4c676709117010e6d07bffafb2c8e6c5#foot-fn2"><sup>1</sup></a>In this paper we use <em>AI-infused systems</em> to refer to systems that have features harnessing AI capabilities that are directly exposed to the end user.</p> <div class="bibStrip"> <p>Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than the author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from <a href="mailto:permissions@acm.org">permissions@acm.org</a>.</p> <p><em>CHI '19, May 04–09, 2019, Glasgow, Scotland UK</em></p> <p>© 2019 Copyright held by the owner/author(s). Publication rights licensed to ACM.<br> ACM ISBN 978-1-4503-5970-2/19/05…$15.00.<br>DOI: <a class="link-inline force-break" target="_blank" href="https://doi.org/10.1145/3290605.3300233">https://doi.org/10.1145/3290605.3300233</a> </p> </div> </section>   
</body></html>