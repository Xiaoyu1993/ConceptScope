Trigger-action programming (TAP) is a programming model enabling users to connect services and devices by writing if-then rules. As such systems are deployed in increasingly complex scenarios, users must be able to identify programming bugs and reason about how to fix them. We first systematize the temporal paradigms through which TAP systems could express rules. We then identify ten classes of TAP programming bugs related to control flow, timing, and inaccurate user expectations. We report on a 153-participant online study where participants were assigned to a temporal paradigm and shown a series of pre-written TAP rules. Half of the rules exhibited bugs from our ten bug classes. For most of the bug classes, we found that the presence of a bug made it harder for participants to correctly predict the behavior of the rule. Our findings suggest directions for better supporting end-user programmers.
The power of data-driven services and the Internet of Things (IoT) centers on interconnections between components. While users could plausibly specify how IoT devices and online services interact using a variety of interaction methods, both industry and academia have repeatedly turned to end-user programming, especially trigger-action programming (TAP). In TAP, a user creates rules of the form “IF a trigger occurs, THEN perform an action.” For example, users can write rules such as, “IF someone tells the voice assistant they are sad THEN turn the lights blue.” This paradigm is the basis for the popular website IFTTT (“If This, Then That”), Microsoft Flow, Zapier, Mozilla's Things Gateway, Stringify, SmartRules, NinjaBlocks, and many others. The TAP approach can be used to connect physical IoT devices, as in the example above, or as a substitute for shell scripting in workplace environments (e.g., allowing novice programmers to write rules that automatically back up data). Academic researchers have recognized the effectiveness of this paradigm for end-user development, conducting a number of studies that rely on TAP or a close variant.
Rules in TAP typically connect a single event to a single action (e.g., “IF I am tagged in a Facebook photo, THEN save that photo to Dropbox”). However, many important behaviors require greater expressiveness. For example, one might want lights to turn on when they arrive home, but only at night. Expressing such a behavior requires that rules support conjunctions (“and” clauses) within triggers. Deployed platforms differ in their support for this. Stringify and SmartRules support conjunctions in a single trigger, while Microsoft Flow and Zapier provide only partial support through trigger filters. While some studies found participants could write rules with conjunctions regardless of their prior programming experience, others highlighted inconsistencies in how users interpret such rules.
To reason about TAP rules unambiguously, it is necessary to fully specify the programming model. We are the first to do so here, delineating three temporal paradigms that could govern how TAP rules are expressed. We identify the syntactic components and limitations of each of these paradigms, providing the first of our three key contributions.
As TAP is deployed in more complex environments, the potential for programming bugs becomes more likely. We identify ten programming bugs that might arise in TAP by re-examining the literature, translating bugs from other domains into TAP, and discussing use cases with scientists deploying a TAP system. To our knowledge, three of these ten bugs are novel within the context of TAP. Of the remaining seven, no single previous paper had identified more than three. We grouped these ten bugs into three classes: bugs in control flow, timing-related bugs, and errors in user interpretation. This taxonomy is our second contribution.
To gauge whether these ten bugs impair user understanding of TAP rules, we conducted a 153-participant online study, our third contribution. We assigned each participant to one of the three temporal paradigms and had them complete a tutorial about TAP. We then showed them a series of TAP rules with accompanying scenarios. In half of these instances, the rules exhibited one of the bugs from our taxonomy. In the other half, the rules were written correctly. We found participants were significantly more likely to accurately predict the behavior of bug-free rules, compared to those exhibiting a bug. We also qualitatively coded participants’ explanations of why they chose each answer to better understand the manifestation of these bugs, to unpack users’ mental models of TAP systems, and to suggest possible interventions.
We begin by discussing related work in Section 2. We then present our systematization of TAP temporal paradigms (Section 3) and our taxonomy of TAP bugs (Section 4). We then describe the methodology (Section 5) and results (Section 6) of our user study. Finally, in Section 7, we discuss directions for helping users avoid these bugs.
End-user development has long been an area of interest within context-aware systems and IoT environments, as well as for web mash-ups. The ubiquity of TAP-like formulations of end-user programming may reflect users’ mental models. Dey et al. found that users often specified behaviors for context-aware applications in an if-then style, while Ur et al. found that many desired behaviors in smart homes could be expressed with TAP. Pane et al. found similar results for programming solutions expressed by non-programmers. These results may reflect, however, the framing of tasks by researchers, rather than inherent mental models. Nonetheless, multiple studies have found that users can write TAP programs regardless of prior programming experience, as demonstrated by thriving real-world TAP ecosystems like IFTTT.
There are drawbacks to current TAP interfaces, however. Many do not support desired complex functionality, many TAP interfaces lack feedback during rule creation, and temporal issues in TAP can lead to inaccurate mental models. Initial attempts to mitigate some of these problems leverage techniques typical of software engineering, including formal verification, information-flow control, privilege isolation, and dynamic instrumentation.
The temporality of triggers and actions is a crucial source of ambiguity for TAP. Prior work by Ur et al. and by Huang and Cakmak noted this difficulty, distinguishing between triggers based on events (things that occur at a moment in time) and states (conditions that are true over a period of time). Here, we adopt the following terminology:
We also distinguish between the following types of action:
Prior work has identified ambiguities caused by temporality. It has not, however, formalized or united the conflicting interpretations. We do so here, proposing three temporal paradigms within which users can write TAP rules with unambiguous meaning. Rulesets in one temporality may be translated to any other.
Table 1 summarizes the paradigms: Event–Event; State–State; and Event–State. This systematization is important because the literature is inconsistent in handling temporality. Some prior studies considered only event triggers, some considered only state triggers, and still others distinguished between (and used) both. Alarmingly, other work has used both types of triggers without specifying how such rules would function.
As TAP is often event-driven, combinations of events would seem to be a viable candidate for triggers. A crucial observation, however, is that events do not compose well—they are unlikely to occur at the exact same instant in time. Therefore, the Event–Event paradigm uses time windows (e.g., “IF Sally enters the bedroom AND the sun sets WITHIN 2 hours”) to account for events not occuring simultaneously. When any event that is part of the trigger occurs, the TAP system would look back in its history to determine whether all other events in the trigger had occurred within the time window. If they had, it would execute the rule's action.
To enable particular orderings of events, we also support “and afterwards.” For example, “IF the sun sets AND AFTERWARDS Sally enters the bedroom WITHIN 2 hours” will only trigger if Sally enters the bedroom after the sun sets.
The Event–State paradigm requires that each trigger contain one event, with zero or more states. When an event trigger occurs, the system would check whether the trigger's states are true. The rule triggers if and only if all specified states are true at the moment the event trigger occurs. Unfortunately, prior research has shown that the distinction between events and states is lost on many users. Nonetheless, the Event–State paradigm is used in the real-world deployments of Stringify and SmartRules, as well as in many academic studies.
In the State–State paradigm, triggers only contain states (e.g., “IF it is currently raining AND I am currently at home”). Because state triggers are true over an interval of time, state actions are most natural (e.g., “the lights should currently be blue”), though it is also possible to include events as actions. Because multiple states can be true simultaneously, rules affecting the same capability (e.g., controlling the lights) must include a prioritization to resolve conflicts. We expand on this in Section 4 through the Priority Conflict bug.
Because some actions (e.g., sending an email) are discrete events that cannot be expressed as state actions in a straightforward way, in Table 1 we provide State–State formulations for both state actions and event actions. Additionally, supporting event actions within State–State introduces complications. Consider the rule “IF I am hungry, THEN order a pizza.” While one is hungry, this rule continually evaluates to true and thus continually triggers, ordering many pizzas.
Neither “or” nor “not” operators are necessary in TAP semantics. Triggers involving “or” can be expressed as separate rules. Note that we used “or” in our user study to separate rules in a ruleset, as discussed in Section 6. The “not” operator is not needed because the negation of a state trigger can be encoded in the state itself (e.g., “it is not raining”), whereas the negation of an event requires a notion of history (e.g., a given event has not occurred in a specified time period).
In this section, we taxonomize ten bugs that might arise in TAP. Four of these bugs (Priority Conflict, Secure-Default Bias, Extended Action, and Missing Reversal) have been discussed at length in TAP literature, while three (Infinite Loop, Repeated Triggering, and Nondeterministic Timing) have been identified but not fully discussed. The remaining three (Contradictory Action, Time-Window Fallacy, and Flipped Triggers) are, to our knowledge, new to the TAP literature.
Our methodology for uncovering these bugs consisted of three activities: re-examining the literature on TAP, attempting to translate bugs observed in novice programming and distributed systems to TAP, and discussing desired use cases and implementation pain points with scientists deploying their own TAP system. Naturally, no bug taxonomy is complete. We anticipate new bugs could be discovered in long-term field studies that uncover complex interactions over time. Logging the use of TAP systems and evolution of rules over time could also provide insight into new bugs. However, we expect our taxonomy captures common bugs.
Some TAP bugs may impair proper control flow.
Infinite Loop bugs arise when rules trigger each other, leading to loops. For example, if a user wants to add items to their to-do list when a file is placed into a to-do folder and save a file in their to-do folder when an item is added to their to-do list, a naive implementation could lead to a never-ending storm of new files as one rule triggers the other. This bug has been encountered within end-user programming of robots. Static or dynamic analysis could detect this bug.
Contradictory Action bugs describe an infinite loop over an extended period of time. For example, a naive set of rules that turn on the heat if the temperature drops below a threshold and turns on air conditioning above the threshold could result in a system that does not converge to an ideal temperature. The TAP literature does not identify this specific form of bug, though Brich et al. studied the related issue of unintended side effects in TAP programming. This bug is difficult to detect in static or dynamic analysis.
Repeated Triggering is when users expect a rule to only trigger once, yet it triggers multiple times. For example, traveling on a road that varies between 0.9 miles and 1.1 miles from a pizza shop can cause “IF I come within 1 mile of a pizza shop THEN order me a pizza” to order many pizzas. This bug is particularly common in the State–State paradigm, where triggers are states that are true over long periods of time. Repeated Triggering was briefly noted in work on mashup programming. Static analysis can detect possible Repeated Triggering, but cannot determine if it is intentional.
Timing bugs, common in distributed systems, are also possible in TAP. Prior work found novice programmers in non-TAP contexts struggle to reason about concurrency.
Nondeterministic Timing bugs arise due to nondeterminism of the order in which a system processes simultaneous triggers. Given the rules “IF the clock strikes 8:00 PM AND it starts raining WITHIN ten minutes THEN turn off the lights” and “IF the clock strikes 8:01 PM AND it starts raining WITHIN ten minutes THEN turn on the lights,” rain that starts at 8:05 PM will trigger both simultaneously. Whether the light is now on or off depends on the order in which the system processes the rules. This bug is frequent in the distributed systems literature, and Huang and Cakmak describe it briefly within TAP. Static and dynamic analysis can detect potential Nondeterministic Timing bugs.
Extended Action bugs are due to actions that occur over time, rather than instantaneously, such as brewing coffee. A rule designed to brew coffee when no coffee is ready would continue to trigger when coffee is brewing (but not yet ready), potentially leading to excess coffee. Although Huang and Cakmak described extended actions, the particular Extended Action bugs that result are an extension of their work.
Bugs in users’ mental models, which can arise from novice programmers ascribing systems intelligence beyond what they possess, may also arise in TAP.
Missing Reversal bugs occur when a user creates a rule that performs some action, yet neglects to write a rule undoing that action. For example, “IF I walk into the living room THEN turn on the lights” turns on the lights when a person enters, yet performs no action when they leave. Prior work has found that users expect such rules to automatically revert themselves when appropriate. Huang and Cakmak discussed Missing Reversal at length, noting users expect systems to have a default regardless of semantics. Static analysis can detect, but not always fix, a Missing Reversal.
Secure-Default Bias bugs occur when users assume a system defaults to a safe state, such as windows remaining locked at night. However, in the most widely deployed paradigm, Event–State, devices do not have default states. Yarosh and Zave discuss this bug in the context of locks.
Time-Window Fallacy bugs occur when users ignore the time window specified by a ruleset constructed in the Event–Event paradigm in favor of a more intuitive interpretation, particularly for rulesets that are more naturally expressed in other temporal paradigms. This bug was not previously noted, likely because prior work left the composition of multiple events as ambiguous.
Priority Conflict occurs when multiple State–State rules act on the same device, causing the need for rule prioritization. Prior work has found that users struggle to prioritize rules to match their intent. Prioritization is essential when multiple rules act on the same device, and when rules act on distinct devices with similar results (e.g. turning on lights and raising blinds to cause more light). The Priority Conflict bug has been discussed extensively in the TAP literature. Static analysis can detect this.
Flipped Triggers occur when users struggle specifying which part of a trigger should be an event and which should be a state. For example, a user might confuse “IF the garage door opens WHILE it is raining, THEN close the garage door” with the subtly different “IF it starts raining WHILE then garage door is open, THEN close the garage door.” However, these rules behave differently. This bug does not appear in previous TAP literature, although the Event-State paradigm has been studied. Formal methods can produce a rule's complement, but cannot determine when it is appropriate.
To gauge whether the bugs we identified lead to misinterpretation of TAP rulesets, we conducted an online user study. We recruited participants on Amazon's Mechanical Turk, requiring they be 18+ years of age, located in the USA, and have at least a 95% approval rating with at least 100 tasks completed. The study took approximately one hour, for which we paid $10. We randomly assigned each participant to one of the three temporal paradigms described in Section 3. The participant then completed a tutorial about the semantics of their assigned paradigm, answering comprehension questions.
The bulk of the study was a series of scenarios. Each described an intended goal, provided a set of TAP rules attempting to achieve that goal, and gave a detailed description of what occurs. Based on the ruleset shown, participants answered a multiple-choice question about the scenario outcome (e.g., whether the lights would be on or off). Whether participants chose the answer accurately predicting the outcome is their correctness. Participants also rated their confidence and provided a free-text explanation of their choice.
For each bug in our taxonomy, we created two scenarios in different domains, termed Scenario One and Scenario Two. For inspiration, we examined the TAP literature and discussed use cases with scientists who have implemented TAP-like rules for the Globus system. For each scenario, we created rulesets in each temporal paradigm to which that bug applied. In addition, for each scenario in each paradigm, we created both a buggy and a fixed ruleset. In the buggy version, the rules shown exhibited the bug, while in the fixed version, they did not. All other aspects remained constant.
For each bug applicable to their assigned paradigm, the participant saw one scenario with its fixed ruleset, and the other with its buggy ruleset. Of the ten bugs, seven applied to Event-State, while eight each applied to State-State and Event-Event. Thus, Event-State participants saw 14 scenarios, whereas all others saw 16 scenarios. For each bug, which scenario was fixed and which was buggy was randomized, as was the overall order of all 14–16 scenarios.
The study concluded with questions about demographics, background in computer programming, and familiarity with both TAP and IoT devices. As we hypothesized that facility with logical thinking might impact performance, we also asked the three-question Cognitive Reflection Test.
We provide the full study instrument in our online appendix. Here, we provide an example of one scenario in one paradigm. We presented scenarios in a visual format similar to the IFTTT interface as IFTTT is widely used.
Scenario One for Flipped Triggers had the following stated goal: “You do not want your dog Fido playing outside in the rain, since he will track mud back indoors.” In the Event-State paradigm, the buggy rule was the following: 0.75cm0.75cm IF  [It starts raining]WHILE [Fido is outside]THEN [Call Fido inside]
Events were always shown in green IFTTT-like boxes and states in purple boxes. We avoided using loaded colors (e.g., red, orange) for items, but otherwise the choice is arbitrary.
We described the scenario as follows: “At 2:00 PM, it begins to rain, and continues raining. At 2:30 PM, Fido goes outside. At 2:31 PM, will Fido have been called inside?” Participants could choose from the following:
Participants then rated their confidence and answered “Why?”
In this example, the correct outcome is “Fido will not have been called inside,” contrary to the stated scenario goal. This rule exhibits the Flipped Triggers bug. To trigger the rule in this scenario, the event portion of the trigger must be swapped with the state portion, as it is in the fixed version.
For bugs like Repeated Triggering, we needed to measure the participant's expectation of the number of times an action occurs, rather than just whether it occurs. Therefore, we presented participants with four choices (e.g., exactly one pizza will have been ordered, the number of pizzas ordered cannot be determined, no pizzas will have been ordered, and more than one pizza will have been ordered).
Our analysis had three goals. First, we wanted to understand if the temporality, the choice of scenario, and whether fixed or buggy rules were seen influenced correctness. Second, we wished to understand participants’ TAP mental models and understanding of the bugs. Third, we wanted to test the impact of demographics and prior experiences.
Toward the first goal, we built a mixed-effects logistic regression model for each bug. The dependent variable was whether each participant answered each scenario correctly (1) or incorrectly (0). The independent variables (IVs) were which temporal paradigm the participant was assigned, which scenario was being tested, and the ruleset's bugginess (buggy or fixed). Each of these IVs was categorical with respective default categories “Event-State,” “Scenario One,” and “fixed.” We included terms capturing the interaction between the bugginess and the two other IVs. We used a mixed-effects model with the participant ID as a random effect because each participant answered two scenarios per bug. If a bug applied to only one paradigm, we excluded the paradigm IV.
For the Secure-Default Bias bug, our correctness comparison differed slightly. Scenario One was hypothesized to trigger the Secure-Default Bias because it involved criminal alerts and locks, while Scenario Two was hypothesized not to do so because it involved weather alerts and the color of lights in a garden. For this bug, the scenario IV and its interaction was thus especially important.
To pursue our second goal, we performed qualitative coding on the free-text “Why?” responses. A first coder performed open coding and created a codebook, assigning one class of code for whether the response demonstrated recognition of the bug, and another class of code for any extra assumptions encoded in the justification. The second coder independently used that codebook to code all data, and the coders met to resolve discrepancies. Cohen's κ was 0.795 and 0.919 for the two classes of codes, respectively.
Toward our third goal, we built two additional linear regression models. The dependent variables were the participant's overall correctness (# correct answers / # scenarios seen) and mean confidence self-rating across questions. The IVs encompassed the participant's demographics, CRT score, correctness on tutorial comprehension questions, and prior experience with TAP, computer programming, and the IoT.
Our study has several limitations. First, we used a convenience sample that may not capture actual users of TAP interfaces. Second, the framing of our system introduces confounds. We chose an abstraction centered on devices because it has been widely deployed to date, priming participants to think in a certain way. We explained in the tutorial, “you will be asked to decide whether or not certain actions take place in these scenarios based on the rules presented” and to “assume no other rules are present,” but prior experiences with IoT devices (e.g., Amazon Echo) with machine learning might bias participants to assume all IoT systems are “smart.”
Some rulesets we tested are more complex than those seen in widely deployed TAP instantiations like IFTTT. As TAP is deployed for a larger number of systems in the future, however, ruleset complexity promises to increase. Finally, interpreting pre-written programs and creating programs are very different. The former can unpack mental-model errors, but program creation is the true goal. Our work should be augmented by studies in which participants create TAP rules.
We first introduce our participants and summarize which factors impacted their correctness. We then describe aspects of participants’ mental models that manifested across scenarios. Subsequently, we detail results for each of the ten bugs. Finally, we describe demographics and experiences correlated with participants’ correctness and confidence.
We had 153 participants ranging in age from 21–69. Among participants, 83 identified as female, 68 as male, and 2 preferred not to answer. Education levels ranged from high school degrees to post-graduate degrees, the largest categories of which were “4-year college degree” (57) and “some college with no degree” (34). Of the 153 participants, 23 majored in, held a degree in, or had held a job in CS-related fields, and 42 had studied computer programming. In total, 63 participants had 15 different types of IoT devices, including voice assistants (47), thermostats (12), and lightbulbs (8).
Our logistic regression models for each bug allowed us to evaluate whether the temporal paradim and the presence or absence of the bug itself (buggy vs. fixed ruleset) impacted the correctness of participants’ multiple-choice answers about the outcome of each scenario. It also allowed us to check whether correctness varied across the two scenarios for each bug. Table 3 summarizes the significant factors in these regressions, while Appendix A in the online supplementary materials presents the full models.
For seven of the ten bugs, participants who saw the buggy ruleset were significantly less likely to choose the correct outcome, compared to those who saw the fixed ruleset (see Figure 1). For two bugs, Repeated Triggering and Time-Window Fallacy, we did not observe a significant effect. For the final bug, Secure-Default Bias, whether the ruleset was buggy was not significant. However, the scenario term in the regression actually encapsulated this bug, as detailed later in the paper, and this term was significant. Thus, the Secure-Default Bias also led to significantly less correct answers. In total, we found evidence that eight of the ten bugs we examined impaired participants’ ability to predict scenario outcomes.
The temporal paradigm also significantly impacted correctness. Compared to Event–State, the baseline in our regression, participants in the Event–Event paradigm were significantly less correct for three bugs, while participants in the State–State paradigm were significantly more correct for one bug. Despite our best efforts to make equally difficult scenarios for all bugs other than Secure-Default Bias, responses to Scenario Two were significantly less correct than for Scenario One for two bugs, and significantly more correct for one bug. We also observed a handful of significant interactions between terms, detailed later in this section. 

We qualitatively coded participants’ free-text explanations of why they chose particular outcomes. As we detail individual bugs, we discuss bug-specific assumptions participants made. However, we also observed some high-level trends in participants’ mental models of TAP.
Some participants consistently struggled to distinguish between events and states, even in paradigms like Event–Event or State–State with only one or the other. This confusion also underlies the Flipped Triggers bug. Participants often tended to think in either one manner or the other, underscoring the importance of defining unambiguous semantics for TAP (Section 3) and clearly communicating them to users.
Participants also expressed uncertainty about the interaction between a TAP system and outside actions, such as someone turning off lights by flipping a switch. Assumptions about the outside world were a key impediment to correct predictions of scenario outcomes. While this confusion may have been heightened by the artificial nature of an online user study, interactions between TAP and physical controls are a likely source of confusion in real systems, as well.
Finally, particular semantics we tested also caused confusion. Event–Event includes “afterwards” to force an ordering of triggers, yet this caused confusion. While negation can be fully encoded in carefully designed triggers without including a “not” operator (Section 3), we tested some scenarios with a “not” operator, and participants struggled.
In this and the following sections, we give detailed results for each bug. The control-flow bugs challenged participants.
Infinite Loop was tested in scenarios predicting whether email attachments would synchronize with a computer folder or text messages. Buggy rulesets automatically forwarded items from one to the other, creating an infinite loop. Fixed rulesets checked the sender or item to avoid duplicates.
Participants correctly predicted outcomes significantly more often with fixed rules — 59.8% of the time — than with buggy rules — 46.1% of the time (OR=0.361, p=0.032). The paradigm and scenario did not have a significant impact.
Of participants who correctly predicted the outcome of buggy rulesets, 81.4% of free-text responses displayed recognition of the bug. For example, “This is a rule with an event as an action that does not specify a time period in the trigger. Therefore, the rule is going to keep triggering. It is going to be going in a loop.” The remaining responses were too vague to ascertain whether or not the bug was recognized.
Surprisingly, 17.1% of participants who were incorrect nonetheless mentioned the bug in their justification. Of this 17.1%, 57.1% mentioned other assumptions that led to an incorrect prediction. In particular, they assumed the user may have read the email before the trigger was evaluated (2 participants), that the system automatically would recognize when files were duplicates (2), that the rule would not trigger on emails sent by another rule (1), or that rules were mutually exclusive (1). That is, some participants ascribed to the system internal intelligence and consistency.
Contradictory Action bugs were tested in scenarios controlling temperature in a house and generators in a power plant. Buggy rulesets caused one rule to eventually trigger another, contradictory rule (e.g., heating the house eventually triggered a rule that cools the house by opening windows).
While participants correctly predicted the outcome 60.5% of the time with fixed rules, they did so only 50.7% of the time with buggy rules (OR=0.190, p=0.001). The scenario (OR=0.182, p<0.001) and the interaction of the scenario and whether the rules were buggy (OR=6.156, p<0.001) also impacted correctness (negatively and positively, respectively).
Our coding found 55.4% of justifications for correct responses mentioned the bug. One noted, “After 10 minutes with the window open the interior would be the same 60 degrees as outside so it would trigger the thermostat, after another 10 minutes [...] it would [...] trigger the other rule.” An additional 24.3% of justifications for correct answers did not mention the bug, while 20.3% were ambiguous.
None of the justifications for incorrect answers mentioned the bug. While 86.3% of these responses did not indicate a clear reason for giving the wrong answer, the remaining 13.7% demonstrated misuong>standings. Three participants thought that rules controlling generators could not trigger while the generators were turning on. Two believed the system would not continuously poll a rule after their triggers had initially been checked and found to be false.
Repeated Triggering was tested with scenarios predicting how many pizzas would be ordered or how many alerts from a motion sensor would be sent. Buggy rulesets had no rate-limiting clauses, making rules trigger repeatedly. Fixed rulesets augmented triggers so rules triggered only once. Repeated Triggering occurs either when a state is continuously true or an event occurs multiple times. We thus used similar, yet somewhat different, scenarios in each paradigm.
The impact of the Repeated Triggering bug appears to depend on the temporality. In our regression model, we did not find the choice of a fixed or buggy ruleset to significantly impact correctness, yet we observed a significant negative interaction between buggy rules and the State–State paradigm (OR=0.119, p=0.005). As shown in Figure 1, participants were more likely to answer correctly for fixed rules than for buggy rules in the State–State paradigm, yet the opposite was true for both the Event–Event and Event–State paradigms. Compared to Event–State, answers overall in Event–Event were less likely to be correct (OR=0.299, p=0.014).
The free-text justifications partially explain these mixed quantitative results. In Event–Event, 15.9% of participants who answered incorrectly struggled with the “not” operator we included in this study, believing the end of the time window was when the truth of the trigger was evaluated. We thus advise against supporting “not” operators. An additional 9.1% appeared to misread the description, while another 6.8% expressed confusion about the trigger.
Both Timing Bugs proved challenging for participants.
Nondeterministic Timing involved evaluating scenarios with simultaneous phone calls or texts, as well as individuals arriving at work the instant the clock struck 9:00. Buggy rulesets left ambiguous the order in which rules triggered. Compared to 83.6% correctness for fixed rules, correctness for buggy rules was only 22.4% (OR=0.159, p<0.001). Furthermore, buggy rules and State–State had a significant positive interaction (OR=16.112, p=0.004). Among justifications from participants who answered correctly for buggy rules, 22.6% explicitly mentioned this nondeterminism, lower than for other bugs. Of participants who did not mention the bug, 16.6% assumed an ordering that made intuitive sense to them, 12.5% did not believe there was physically enough time for the notifications to trigger, and 8.3% assumed the full time window had to pass before rules triggered.
Of participants who were incorrect, 29.7% nonetheless recognized that there might be buggy behavior. The majority, 51.4%, assumed an incorrect ordering that made intuitive sense to them, while 37.1% incorrectly assumed the “afterwards” keyword would resolve uncertainty.
Extended Action involved scenarios in which industrial robots ran chemical reactions and coffee brewed. Buggy rulesets would trigger additional rules while these extended actions were in process, yet not complete. Participants correctly predicted outcomes more often (47.6% of the time) with fixed rules than with buggy rules (19.0% of the time) (OR=0.164, p=0.015). Only 5.9% of participants who answered incorrectly for buggy rules mentioned the bug in their response (e.g., “More than one cup could brew”). Participants often ignored the rules’ semantics in favor of an intuitive interpretation; 41.1% assumed actions would not buffer, while 20.6% believed they would. Others misread the question (17.6%), assumed extended actions would cease if a state trigger became false (5.9%), or confused events and states (5.9%).
Four of the five bugs we tested related to potentially incorrect user expectations proved problematic for participants.
Missing Reversal was tested in scenarios involving controlling living room lights or house windows. Buggy rulesets turned lights on and closed the windows, but did not include any rules to reverse those actions. Participants were correct 86.2% of the time for fixed rules, but only 63.8% of the time for buggy rules (OR=0.156, p=0.046). The scenario (OR=0.254, p=0.018) and, relative to Event–State, the Event–Event paradigm (OR=0.256, p=0.022) negatively impacted correctness.
Overall, 79.4% of participants who answered correctly for buggy rules mentioned the bug in their justification (e.g., “There is no rule to open the windows after it stops raining”). The remaining 20.6% either re-stated the scenario or made vague statements (e.g., “it's just obvious”).
Surprisingly, 40.0% of participants who answered incorrectly nonetheless mentioned the potential for buggy behavior. Six of them anticipated out-of-system manual interactions (e.g., “The rule never turns the lights off, only on. So, they must be turned off manually”), which our tutorial said to ignore. Five believed additional rules might exist (“There may or may not be a rule to re-open the windows”), also disallowed by our tutorial. Two others treated events as states.
Secure-Default Bias was tested differently than other bugs. Instead of comparing buggy and fixed rules, we compared two scenarios with parallel wording. An innocuous Scenario One discussed “weather alerts” and changed the color of garden lights, whereas a security-critical Scenario Two substituted “criminal alerts” and controlled door locks.
Participants correctly predicted scenario outcomes more often in the innocuous scenario — 65.8% — than when shown the security-critical scenario — 61.2% (OR=0.367, p=0.043). Furthermore, compared to Event–State, State–State answers were more likely to be correct (OR=10.075, p=0.002), though our qualitative coding sugggests this difference may derive from ambiguous wording in our survey across temporalities.
Overall, 72.8% of justifications from participants who answered correctly for buggy rules mentioned the bug. One stated, “The rule to unlock the door from 7-8pm has a higher priority than the criminal alert rule and so the doors will be unlocked then, regardless of the criminal alert.” The remaining participants in this category wrote vague justifications.
Among participants who were incorrect, 26.7% explicitly displayed a Secure-Default Bias. In contrast, the majority who did not recognize the bug displayed a few different misunderstandings. For example, 18.2% misunderstood the State–State priority system, while 13.6% incorrectly believed the order in which events occurred would lead one to “override” the other (e.g., “Because the criminal alert was issued before 7pm, it would automatically override the ’unlock’ command at 7”). This was unique to the Secure-Default Bias, suggesting that it may also be a manifestation of the bug.
Time-Window Fallacy, exclusive to Event–Event, was tested in scenarios involving alerts based on the arrival of data or a person at the door. In buggy rulesets, the time window extended beyond when the activity was occurring. Thus, the rule would still trigger. The fixed version set a smaller time window that better matched the activity.
Neither the ruleset nor any other factor we tested significantly impacted correctness, which was high overall. Furthermore, 84.4% of participants who answered correctly for buggy rules explicitly mentioned the bug in their justification. Overall, this potential bug appears not to be problematic.
Priority Conflict was tested in scenarios about controlling lights. Buggy rulesets incorrectly applied equal priority to conflicting rules. Fixed rulesets used unique priorities.
Participants correctly predicted scenario outcomes more often — 59.5% — for fixed rules than buggy rules — 40.5% (OR=0.154, p=0.004). Furthermore, buggy rules interacted significantly with the scenario (OR=9.89, p=0.013).
Among participants who answered correctly for buggy rules, 88.2% of their justifications mentioned the bug. One noted it well: “It could go either way because all the rules are met and there is no difference in priority.” Of participants who were incorrect, only 24.4% mentioned potential bugs.
Flipped Triggers was tested in scenarios involving calling a dog in from the rain and pairing Bluetooth devices. While the fixed rules triggered in the scenario given, the buggy rules would have triggered only if the event and state (or the two events) in the trigger were swapped. We thus searched for incorrect expectations of the swapped version also triggering the rule despite the rule stating otherwise.
Indeed, 82.7% of participants answered correctly for fixed rules, compared to only 60.9% for buggy rules (OR=0.197, p=0.022). The scenario (OR=5.89, p=0.009), the Event–Event paradigm (OR=0.155, p=0.006), and the interaction between the ruleset and the scenario (OR=0.189, p=0.035) all had significant interactions. Overall, 89.6% of participants who answered correctly for buggy rules mentioned either the bug or the correct semantics of the triggers in their response. For example, “Fido was not outside when it began to rain. It started raining first and then Fido went outside.”
Among participants who were incorrect, only 13.9% mentioned the possibility of the bug. While 35.1% seemed to misunderstand the “afterwards” keyword, the majority exhibited the Flipped Triggers bug.
To test the effects of demographic factors and prior experiences with relevant technologies, we built a linear regression model with the overall percentage of scenarios a participant answered correctly as the dependent variable (Appendix A). We built an analogous model for average confidence ratings.
Participants who had prior programming experience answered more correctly (β = 0.083, p = .038), but were less confident in their answers (β = −0.363, p = .006). In contrast to prior work that found programming experience was not a significant factor in TAP correctness, this discrepancy may derive from differences in the studies. The prior study focused on simpler scenarios without intentionally buggy behavior. Our study instead focused on challenging situtations. In these situations, users with programming experience may look for edge cases, which we observed in free-text justifications. For example, asked whether a dog would be called indoors, one participant noted, “This depends on the dog. Just because you call him in doesn't mean he will come in.”
Participants’ logical thinking, measured with the CRT, was also correlated with greater correctness (β = 0.038, p = .006). Unsurprisingly, participants were more confident in their answers if they had used IFTTT (β = 0.312, p = .009) or did better on the tutorial questions (β = 0.106, p = .026).
Despite recent interest, most literature treats TAP temporality imprecisely, preventing systematic evaluations in complex situations. We thus defined semantics that unambiguously express TAP rules in three temporal paradigms. We also synthesized a taxonomy of ten bugs likely to impact TAP systems. Of the ten, three were completely novel, and no single prior paper had collected more than three. This taxonomy can serve as a roadmap for developing end-user debugging tools. To gauge if these bugs impair users’ ability to predict TAP outcomes, we conducted a 153-participant online study. Participants interpreted TAP rules in scenarios designed to elicit these ten bugs. Eight of these bugs impaired participants’ ability to correctly predict scenario outcomes.
Significant research in software engineering addresses bug detection, but less work focuses on debugging in end-user programming. The Priority Conflict, Infinite Loop, Extended Action, and Nondeterministic Timing bugs can potentially be detected by static analysis. Prior work has already shown success in combatting Priority Conflict bugs, though current static analysis techniques may be insufficient to fully handle Infinite Loop bugs. To address Extended Action bugs, a system could highlight that the action is extended, asking users about expected behaviors. To address Nondeterministic Timing bugs, the system could analyze rules that might conflict, asking for a priority ordering. Our results showed that some participants were unable to detect these bugs by themselves. Many studies have noted, however, that feedback during rule creation can enable end-users to correct simple bugs when notified.
The Contradictory Action and Repeated Triggering bugs can only be detected at runtime. This is because current formal methods cannot model a system's self-interference. Thus, Contradictory Action bugs should be met with pattern analysis in system logs. Repeated Triggering bugs require heuristic methods to resolve. Static analysis can suggest when these bugs might be present, but some situations are intentional (e.g. ordering many pizzas for a party).
The remaining bugs cannot be detected automatically, either because the situation is ambiguous (Secure-Default Bias, Time-Window Fallacy), or because suggestions for fixes may be incorrect (Missing Reversal, Flipped Triggers). Whie the Time-Window Fallacy did not impair understanding in our study, the others did. Recent work combining formal methods with user-specified properties (e.g., “the window is open AND it is raining SHOULD NEVER OCCUR TOGETHER”) may help users identify and repair such bugs.
Correctness cannot be achieved with bug detection alone. Interfaces that support effective end-user debugging are critical. A lack of feedback during rule creation is a key impediment to creating correct TAP rules. The simplest type of feedback would be an interface highlighting rules that might suffer from a bug. For less challenging bugs, this may be sufficient. Automatically suggesting potential fixes (that may or may not match user intent) during rule creation might help. Seeing a proposed fix might be sufficient to show the user why the fix is necessary or not. For example, a system could show the user a rule's Flipped Triggers reversal, hoping that this will be enough for a user to decide whether they need that variant. The user must be deeply involved in this process, though, because correctness is often subjective, and suggested rules may not match their intent.
The limited work thus far on debugging smart homes has focused on providing retroactive insight into why unintended behaviors triggered. For example, Mennicken et al. proposed a calendar-based interface for this purppose, in line with work on interrogative debugging for end-user programming. Plausibly, users could also provide feedback to the system, specifying undesirable behaviors and asking why are occurring. Model checking techniques could also identify when rules would cause these behaviors.
However, we propose that interfaces could instead proactively simulate the rule outcomes. For example, a system could ask the user whether the lights should be on or off in a given scenario, then use the answer to choose among synthesized rules or prioritize existing rules. Interfaces could visualize concrete differences between when subtly different rules would have triggered in the past, or might in the future.
This material is based upon work supported by the National Science Foundation under Grants No. 1837120 and 1835890.
